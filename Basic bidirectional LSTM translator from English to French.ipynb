{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASIC BIDIRECTIONAL RECURRENT NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I am going to design and develop a basic bidirectional RNN with Pytorch and CUDA. The goal is to create an English to French translator.\n",
    "\n",
    "To carry out this project I implemented the knowledge I gained in the Udacity Natural Language Processing Nanodegree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jandr\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\jandr\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\jandr\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of project is computationally expensive, for this reason I will use a Dataset created by Udacity that uses a short vocabulary. This way I will test the architecture with a much lower computational and time cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Data\n",
    "The data is located in `data/small_vocab_en` and `data/small_vocab_fr`. The `small_vocab_en` file contains English sentences with their French translations in the `small_vocab_fr` file. Load the English and French data from these files from running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SET LOADED\n"
     ]
    }
   ],
   "source": [
    "# Load English data\n",
    "english_sentences = load_data('data/small_vocab_en')\n",
    "# Load French data\n",
    "french_sentences = load_data('data/small_vocab_fr')\n",
    "\n",
    "print('DATA SET LOADED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase in English:  china is usually pleasant during november , and it is never quiet in october .\n",
      "Phrase in French:  chine est généralement agréable en novembre , et il est jamais tranquille en octobre .\n"
     ]
    }
   ],
   "source": [
    "print('Phrase in English: ', english_sentences[20])\n",
    "print('Phrase in French: ', french_sentences[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create and apply a word counter\n",
    "The following function creates a dictionary with the word count, and return the number of words that have the longest phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_count(texts):\n",
    "    w_count = {}\n",
    "    max_w = 0\n",
    "    \n",
    "    for i in texts:\n",
    "        ws = i.split()\n",
    "        \n",
    "        for w in  ws:\n",
    "            if w not in w_count:\n",
    "                w_count[w] = 1\n",
    "            else:\n",
    "                w_count[w] += 1\n",
    "                \n",
    "        if len(ws)>max_w:\n",
    "            max_w = len(ws)\n",
    "            \n",
    "    return w_count, max_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of words in a english phrase:  17\n",
      "English vocablary size:  227\n",
      "Max number of words in a french phrase:  23\n",
      "French vocablary size:  355\n"
     ]
    }
   ],
   "source": [
    "en_w_count, en_max_w = world_count(english_sentences)\n",
    "print('Max number of words in a english phrase: ', en_max_w)\n",
    "print('English vocablary size: ', len(en_w_count))\n",
    "\n",
    "fr_w_count, fr_max_w = world_count(french_sentences)\n",
    "print('Max number of words in a french phrase: ', fr_max_w)\n",
    "print('French vocablary size: ', len(fr_w_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the word counter we can see that the dataset we are using was carefully created, it does not have a large number of words and all of them are repeated an acceptable number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================  English word counter  ==================== \n",
      " \n",
      " {'new': 12197, 'jersey': 11225, 'is': 205858, 'sometimes': 37746, 'quiet': 8693, 'during': 74933, 'autumn': 9004, ',': 140897, 'and': 59850, 'it': 75137, 'snowy': 8898, 'in': 75525, 'april': 8954, '.': 129039, 'the': 67628, 'united': 11270, 'states': 11270, 'usually': 37507, 'chilly': 8770, 'july': 8956, 'freezing': 8928, 'november': 8951, 'california': 11250, 'march': 9023, 'hot': 8639, 'june': 9133, 'mild': 8743, 'cold': 8878, 'september': 8958, 'your': 9734, 'least': 27564, 'liked': 13546, 'fruit': 27105, 'grape': 4703, 'but': 63987, 'my': 9700, 'apple': 4652, 'his': 9700, 'favorite': 27371, 'orange': 4651, 'paris': 11334, 'relaxing': 8696, 'december': 8945, 'busy': 8791, 'spring': 9102, 'never': 37500, 'our': 8932, 'lemon': 4652, 'january': 9090, 'warm': 8890, 'lime': 4680, 'her': 9700, 'banana': 4652, 'he': 10786, 'saw': 648, 'a': 1944, 'old': 972, 'yellow': 972, 'truck': 1944, 'india': 11277, 'rainy': 8761, 'that': 2712, 'cat': 192, 'was': 1867, 'most': 14934, 'loved': 13666, 'animal': 2304, 'dislikes': 7314, 'grapefruit': 10118, 'limes': 5554, 'lemons': 5533, 'february': 8942, 'china': 10953, 'pleasant': 8916, 'october': 8910, 'wonderful': 8808, 'nice': 8984, 'summer': 8948, 'france': 11170, 'may': 8995, 'grapes': 5525, 'mangoes.': 295, 'their': 8932, 'mango': 4652, 'pear': 4652, 'august': 8789, 'beautiful': 8915, 'apples': 5452, 'peaches': 5451, 'feared': 768, 'shark': 192, 'wet': 8726, 'dry': 8794, 'we': 2532, 'like': 4588, 'oranges': 5452, 'mangoes': 5549, 'they': 3222, 'pears': 5451, 'she': 10786, 'little': 1016, 'red': 972, 'winter': 9038, 'disliked': 648, 'rusty': 972, 'car': 1944, 'strawberries': 5452, 'i': 2664, 'strawberry': 4715, 'bananas.': 392, 'going': 666, 'to': 5166, 'next': 1666, 'plan': 714, 'visit': 1224, 'elephants': 64, 'were': 384, 'animals': 768, 'favorite.': 961, 'are': 870, 'likes': 7314, 'bananas': 5452, 'dislike': 4444, 'fall': 9134, 'driving': 1296, 'oranges.': 392, 'liked.': 500, 'peach': 4652, 'loved.': 500, 'drives': 648, 'blue': 972, 'you': 2414, 'bird': 192, 'grapefruit.': 574, 'horses': 64, 'mouse': 192, 'went': 378, 'last': 781, 'peaches.': 393, 'horse': 192, 'automobile': 1944, 'dogs': 64, 'white': 972, 'elephant': 192, 'lemons.': 311, 'mango.': 196, 'apples.': 392, 'banana.': 196, 'peach.': 196, 'black': 972, 'think': 240, 'difficult': 260, 'translate': 480, 'between': 540, 'spanish': 312, 'portuguese': 312, 'big': 1016, 'green': 972, 'strawberries.': 392, 'translating': 300, 'fun': 260, 'grapes.': 319, 'lemon.': 196, 'where': 12, '?': 811, 'dog': 192, 'why': 240, 'might': 378, 'go': 1386, 'this': 768, 'drove': 648, 'shiny': 972, 'orange.': 197, 'pear.': 196, 'sharks': 64, 'monkey': 192, 'strawberry.': 133, 'how': 67, 'weather': 33, 'lion': 192, 'plans': 476, 'bear': 192, 'pears.': 393, 'apple.': 196, 'rabbit': 192, \"it's\": 240, 'chinese': 312, 'when': 144, 'eiffel': 57, 'tower': 57, 'did': 204, 'grocery': 57, 'store': 57, 'wanted': 378, 'fruit.': 87, 'does': 24, 'football': 57, 'field': 57, 'wants': 252, \"didn't\": 60, 'lime.': 168, 'snake': 192, 'snakes': 64, 'do': 84, 'easy': 260, 'thinks': 360, 'english': 312, 'french': 312, 'would': 48, \"aren't\": 36, 'cats': 64, 'rabbits': 64, 'has': 24, 'been': 36, 'limes.': 290, 'monkeys': 64, 'grape.': 145, 'lake': 57, 'bears': 64, 'school': 57, 'birds': 64, 'want': 126, \"isn't\": 24, 'lions': 64, 'am': 24, 'mice': 64, 'have': 12}\n"
     ]
    }
   ],
   "source": [
    "print('======================  English word counter  ====================','\\n','\\n',en_w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================  French word counter  ==================== \n",
      " \n",
      " {'new': 11047, 'jersey': 11052, 'est': 196809, 'parfois': 37746, 'calme': 7256, 'pendant': 10741, \"l'\": 32917, 'automne': 14727, ',': 123135, 'et': 59851, 'il': 84079, 'neigeux': 1867, 'en': 105768, 'avril': 8954, '.': 135619, 'les': 65255, 'états-unis': 11210, 'généralement': 31292, 'froid': 16794, 'juillet': 8956, 'gèle': 3622, 'habituellement': 6215, 'novembre': 8951, 'california': 3061, 'mars': 9023, 'chaud': 16405, 'juin': 9133, 'légère': 63, 'fait': 2916, 'septembre': 8958, 'votre': 9368, 'moins': 27557, 'aimé': 24842, 'fruit': 23626, 'le': 35306, 'raisin': 4852, 'mais': 63987, 'mon': 9403, 'la': 49861, 'pomme': 4848, 'son': 16496, 'préféré': 22886, \"l'orange\": 4848, 'paris': 11334, 'relaxant': 8458, 'décembre': 8945, 'occupé': 7782, 'au': 25738, 'printemps': 9100, 'jamais': 37215, 'chaude': 1124, 'notre': 8319, 'citron': 4848, 'janvier': 9090, 'chaux': 4848, 'des': 2435, 'fruits': 3566, 'banane': 4848, 'aimé.': 1010, 'a': 1356, 'vu': 645, 'un': 698, 'vieux': 325, 'camion': 1944, 'jaune': 972, 'inde': 11277, 'pluvieux': 7658, 'ce': 1465, 'chat': 192, 'était': 1198, 'animal': 2248, 'plus': 14934, \"n'aime\": 3131, 'pamplemousse': 10140, 'citrons': 11679, 'verts': 5835, 'californie': 8189, 'ne': 2715, 'février': 8942, 'gel': 4886, 'chine': 10936, 'agréable': 17751, 'octobre': 8911, 'merveilleux': 8704, 'doux': 8458, 'tranquille': 1437, 'à': 13870, \"l'automne\": 3411, 'été': 8999, 'france': 11170, 'mois': 14350, 'de': 15070, 'mai': 8995, 'frisquet': 834, 'déteste': 3743, 'raisins': 5780, 'mangues': 5774, 'leur': 7855, 'mangue': 4899, 'poire': 4848, 'août': 8789, 'beau': 6387, 'pommes': 5844, 'pêches': 5844, 'redouté': 576, 'que': 667, 'requin': 192, 'humide': 8446, \"d'\": 5100, 'sec': 7957, 'enneigée': 4008, 'nous': 2520, 'aimons': 1111, 'oranges': 5844, 'ils': 3185, 'aiment': 1116, 'poires': 5844, 'elle': 12056, 'petit': 324, 'rouge': 972, 'cher': 1308, 'aimée': 105, 'neige': 3016, 'trop': 173, 'monde': 173, 'hiver': 9038, 'sont': 1018, \"n'aimait\": 561, 'pas': 4495, 'une': 1278, 'voiture': 3510, 'rouillée': 486, 'fraises': 5844, 'cours': 1927, \"j'aime\": 966, 'fraise': 4848, 'bananes': 5844, 'va': 355, 'aux': 392, 'prochain': 1666, 'je': 1548, 'prévois': 233, 'visiter': 908, 'belle': 2726, 'éléphants': 64, 'étaient': 357, 'ses': 402, 'animaux': 768, 'redoutés': 190, 'vont': 168, 'aime': 8870, 'préférée': 770, \"n'aiment\": 1111, 'i': 150, 'comme': 259, 'conduit': 1706, 'pêche': 4848, 'préféré.': 419, 'nouvelle': 648, 'bleue': 504, 'vous': 2517, 'aimez': 1053, 'cet': 286, 'oiseau': 128, 'pamplemousses': 552, 'pleut': 562, 'magnifique': 104, 'favori': 3857, 'vos': 225, 'aimés': 237, 'chevaux': 64, \"n'aimez\": 1094, \"n'aimons\": 97, 'souris': 256, 'détestons': 1001, 'allé': 187, 'dernier': 757, 'conduisait': 673, 'petite': 615, 'glaciales': 307, 'cheval': 192, 'vieille': 647, 'chiens': 64, 'préférés': 383, 'blanche': 579, 'occupée': 836, 'nos': 613, \"l'éléphant\": 64, 'nouveau': 502, 'noire': 602, 'pluies': 367, 'pense': 540, \"qu'il\": 393, 'difficile': 260, 'traduire': 501, 'entre': 540, 'espagnol': 312, 'portugais': 312, 'bleu': 468, 'rouillé': 454, 'aimait': 707, 'grande': 459, 'verte': 628, 'traduction': 277, 'amusant': 260, 'cette': 1239, 'vert': 344, 'grand': 81, 'blanc': 393, 'volant': 165, 'gros': 258, 'où': 12, 'États-unis': 57, '?': 811, 'chien': 192, 'leurs': 1072, 'pourquoi': 240, '-': 328, \"l'automobile\": 100, 'pourrait': 252, 'se': 461, 'rendre': 350, 'prévoyons': 232, 'maillot': 173, 'grosse': 185, 'brillant': 587, 'prévoient': 75, 'mouillée': 7, 'lui': 70, 'détendre': 111, 'automobile': 278, 'pourraient': 126, 'aller': 1180, 'mes': 297, 'sèche': 837, \"l'oiseau\": 64, 'pluie': 174, 'requins': 64, 'noir': 370, 'singe': 192, 'détestait': 87, 'comment': 67, 'temps': 33, 'dans': 12, 'lion': 192, 'prévoit': 75, 'ours': 192, 'porcelaine': 17, 'clémentes': 200, 'plaît': 13, 'proches': 20, 'brillante': 385, 'lapin': 192, \"l'ours\": 64, 'chinois': 312, 'quand': 144, 'tour': 57, 'eiffel': 57, 'est-ce': 12, 'allons': 45, \"l'épicerie\": 57, 'voulait': 252, 'cépage': 60, 't': 18, 'terrain': 57, 'football': 57, 'du': 39, 'veut': 252, 'éléphant': 128, 'gelé': 94, 'bien': 77, 'enneigé': 7, 'gelés': 5, 'serpent': 192, 'allés': 150, 'allée': 150, 'envisage': 360, 'peu': 41, 'mouillé': 273, 'serpents': 64, 'pensez': 60, 'facile': 260, 'anglais': 312, 'français': 312, 'voulez': 12, 'grandes': 16, 'avez': 162, 'aimeraient': 12, 'allez': 45, 'chats': 64, 'lapins': 64, 'visite': 68, 'ont': 194, 'intention': 206, \"n'est\": 47, '-elle': 24, 'dernière': 24, 'voulaient': 126, 'singes': 64, 'êtes-vous': 24, '-ce': 95, \"qu'elle\": 26, 'vers': 76, 'lac': 57, 'pousse': 41, 'détestez': 17, 'manguiers': 19, 'grands': 9, '-il': 36, \"l'école\": 57, '-ils': 26, \"l'animal\": 56, 'at': 32, 'oiseaux': 64, 'ressort': 2, 'petits': 10, \"n'a\": 12, 'veulent': 126, 'rouille': 32, 'frais': 20, 'limes': 9, 'lions': 64, 'douce': 14, 'envisagent': 9, 'petites': 26, 'vais': 24, 'durant': 14, \"c'est\": 17, 'congélation': 14, 'allions': 1, 'voudrait': 24, 'détend': 2, 'trouvé': 1, 'préférées': 16, 'conduite': 6, 'grosses': 8, 'bénigne': 8, 'avons': 19, 'sur': 28, 'redoutée': 2, 'etats-unis': 3, 'moindres': 7, 'aiment-ils': 10, \"n'êtes\": 3, 'vit': 3, 'as-tu': 1, 'qui': 2, 'faire': 1, 'traduis': 2, 'favoris': 1, 'souvent': 1, 'es-tu': 1, 'apprécié': 2, 'moteur': 1, 'tout': 4}\n"
     ]
    }
   ],
   "source": [
    "print('======================  French word counter  ====================','\\n','\\n',fr_w_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create and apply a word counter\n",
    "\n",
    "Using the word counter I create a function that returns two Dictionary objects.  These dictionaries contain all the words that exceed a minimum number of repetitions in the dataset, and their assigned ID. One of the dictionaries has as key the word and as value the ID, and the other dictionary inverts the key and the value of the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dic(t_count, min_t=1, start=False, end=False, nan=False):\n",
    "    id2t = {}\n",
    "    t2id = {}\n",
    "    id = 0\n",
    "    \n",
    "    if nan == True:                 # There is no word\n",
    "        id2t[str(id)] = '<nan>'\n",
    "        t2id['<nan>'] = id\n",
    "        id += 1\n",
    "    \n",
    "    if start == True:               # start value of the phrase\n",
    "        id2t[str(id)] = '<start>'\n",
    "        t2id['<start>'] = id\n",
    "        id += 1\n",
    "        \n",
    "    if end == True:                 # end value of the phrase\n",
    "        id2t[str(id)] = '<end>'\n",
    "        t2id['<end>'] = id\n",
    "        id += 1\n",
    "        \n",
    "    for i in t_count:               \n",
    "        if t_count[i] >= min_t:    # The word is repeated more than the minimum chosen\n",
    "            \n",
    "            t2id[i] = id\n",
    "            id2t[str(id)] = i\n",
    "            \n",
    "            id += 1\n",
    "            \n",
    "    # add to the dictionary a token and an Id to the tokens that are not in the dictionary\n",
    "    t2id['<str>'] = id            \n",
    "    id2t[str(id)] = '<str>'\n",
    "\n",
    "    return id2t, t2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_id2t, en_t2id = create_dic(en_w_count, min_t=1, start=False, end=False, nan=True)\n",
    "fr_id2t, fr_t2id = create_dic(fr_w_count, min_t=1, start=False, end=False, nan=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**English dictionary whose key is the word and the value is the ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<nan>': 0, 'new': 1, 'jersey': 2, 'is': 3, 'sometimes': 4, 'quiet': 5, 'during': 6, 'autumn': 7, ',': 8, 'and': 9, 'it': 10, 'snowy': 11, 'in': 12, 'april': 13, '.': 14, 'the': 15, 'united': 16, 'states': 17, 'usually': 18, 'chilly': 19, 'july': 20, 'freezing': 21, 'november': 22, 'california': 23, 'march': 24, 'hot': 25, 'june': 26, 'mild': 27, 'cold': 28, 'september': 29, 'your': 30, 'least': 31, 'liked': 32, 'fruit': 33, 'grape': 34, 'but': 35, 'my': 36, 'apple': 37, 'his': 38, 'favorite': 39, 'orange': 40, 'paris': 41, 'relaxing': 42, 'december': 43, 'busy': 44, 'spring': 45, 'never': 46, 'our': 47, 'lemon': 48, 'january': 49, 'warm': 50, 'lime': 51, 'her': 52, 'banana': 53, 'he': 54, 'saw': 55, 'a': 56, 'old': 57, 'yellow': 58, 'truck': 59, 'india': 60, 'rainy': 61, 'that': 62, 'cat': 63, 'was': 64, 'most': 65, 'loved': 66, 'animal': 67, 'dislikes': 68, 'grapefruit': 69, 'limes': 70, 'lemons': 71, 'february': 72, 'china': 73, 'pleasant': 74, 'october': 75, 'wonderful': 76, 'nice': 77, 'summer': 78, 'france': 79, 'may': 80, 'grapes': 81, 'mangoes.': 82, 'their': 83, 'mango': 84, 'pear': 85, 'august': 86, 'beautiful': 87, 'apples': 88, 'peaches': 89, 'feared': 90, 'shark': 91, 'wet': 92, 'dry': 93, 'we': 94, 'like': 95, 'oranges': 96, 'mangoes': 97, 'they': 98, 'pears': 99, 'she': 100, 'little': 101, 'red': 102, 'winter': 103, 'disliked': 104, 'rusty': 105, 'car': 106, 'strawberries': 107, 'i': 108, 'strawberry': 109, 'bananas.': 110, 'going': 111, 'to': 112, 'next': 113, 'plan': 114, 'visit': 115, 'elephants': 116, 'were': 117, 'animals': 118, 'favorite.': 119, 'are': 120, 'likes': 121, 'bananas': 122, 'dislike': 123, 'fall': 124, 'driving': 125, 'oranges.': 126, 'liked.': 127, 'peach': 128, 'loved.': 129, 'drives': 130, 'blue': 131, 'you': 132, 'bird': 133, 'grapefruit.': 134, 'horses': 135, 'mouse': 136, 'went': 137, 'last': 138, 'peaches.': 139, 'horse': 140, 'automobile': 141, 'dogs': 142, 'white': 143, 'elephant': 144, 'lemons.': 145, 'mango.': 146, 'apples.': 147, 'banana.': 148, 'peach.': 149, 'black': 150, 'think': 151, 'difficult': 152, 'translate': 153, 'between': 154, 'spanish': 155, 'portuguese': 156, 'big': 157, 'green': 158, 'strawberries.': 159, 'translating': 160, 'fun': 161, 'grapes.': 162, 'lemon.': 163, 'where': 164, '?': 165, 'dog': 166, 'why': 167, 'might': 168, 'go': 169, 'this': 170, 'drove': 171, 'shiny': 172, 'orange.': 173, 'pear.': 174, 'sharks': 175, 'monkey': 176, 'strawberry.': 177, 'how': 178, 'weather': 179, 'lion': 180, 'plans': 181, 'bear': 182, 'pears.': 183, 'apple.': 184, 'rabbit': 185, \"it's\": 186, 'chinese': 187, 'when': 188, 'eiffel': 189, 'tower': 190, 'did': 191, 'grocery': 192, 'store': 193, 'wanted': 194, 'fruit.': 195, 'does': 196, 'football': 197, 'field': 198, 'wants': 199, \"didn't\": 200, 'lime.': 201, 'snake': 202, 'snakes': 203, 'do': 204, 'easy': 205, 'thinks': 206, 'english': 207, 'french': 208, 'would': 209, \"aren't\": 210, 'cats': 211, 'rabbits': 212, 'has': 213, 'been': 214, 'limes.': 215, 'monkeys': 216, 'grape.': 217, 'lake': 218, 'bears': 219, 'school': 220, 'birds': 221, 'want': 222, \"isn't\": 223, 'lions': 224, 'am': 225, 'mice': 226, 'have': 227, '<str>': 228}\n"
     ]
    }
   ],
   "source": [
    "print(en_t2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**English dictionary whose key is the ID and the value is the word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': '<nan>', '1': 'new', '2': 'jersey', '3': 'is', '4': 'sometimes', '5': 'quiet', '6': 'during', '7': 'autumn', '8': ',', '9': 'and', '10': 'it', '11': 'snowy', '12': 'in', '13': 'april', '14': '.', '15': 'the', '16': 'united', '17': 'states', '18': 'usually', '19': 'chilly', '20': 'july', '21': 'freezing', '22': 'november', '23': 'california', '24': 'march', '25': 'hot', '26': 'june', '27': 'mild', '28': 'cold', '29': 'september', '30': 'your', '31': 'least', '32': 'liked', '33': 'fruit', '34': 'grape', '35': 'but', '36': 'my', '37': 'apple', '38': 'his', '39': 'favorite', '40': 'orange', '41': 'paris', '42': 'relaxing', '43': 'december', '44': 'busy', '45': 'spring', '46': 'never', '47': 'our', '48': 'lemon', '49': 'january', '50': 'warm', '51': 'lime', '52': 'her', '53': 'banana', '54': 'he', '55': 'saw', '56': 'a', '57': 'old', '58': 'yellow', '59': 'truck', '60': 'india', '61': 'rainy', '62': 'that', '63': 'cat', '64': 'was', '65': 'most', '66': 'loved', '67': 'animal', '68': 'dislikes', '69': 'grapefruit', '70': 'limes', '71': 'lemons', '72': 'february', '73': 'china', '74': 'pleasant', '75': 'october', '76': 'wonderful', '77': 'nice', '78': 'summer', '79': 'france', '80': 'may', '81': 'grapes', '82': 'mangoes.', '83': 'their', '84': 'mango', '85': 'pear', '86': 'august', '87': 'beautiful', '88': 'apples', '89': 'peaches', '90': 'feared', '91': 'shark', '92': 'wet', '93': 'dry', '94': 'we', '95': 'like', '96': 'oranges', '97': 'mangoes', '98': 'they', '99': 'pears', '100': 'she', '101': 'little', '102': 'red', '103': 'winter', '104': 'disliked', '105': 'rusty', '106': 'car', '107': 'strawberries', '108': 'i', '109': 'strawberry', '110': 'bananas.', '111': 'going', '112': 'to', '113': 'next', '114': 'plan', '115': 'visit', '116': 'elephants', '117': 'were', '118': 'animals', '119': 'favorite.', '120': 'are', '121': 'likes', '122': 'bananas', '123': 'dislike', '124': 'fall', '125': 'driving', '126': 'oranges.', '127': 'liked.', '128': 'peach', '129': 'loved.', '130': 'drives', '131': 'blue', '132': 'you', '133': 'bird', '134': 'grapefruit.', '135': 'horses', '136': 'mouse', '137': 'went', '138': 'last', '139': 'peaches.', '140': 'horse', '141': 'automobile', '142': 'dogs', '143': 'white', '144': 'elephant', '145': 'lemons.', '146': 'mango.', '147': 'apples.', '148': 'banana.', '149': 'peach.', '150': 'black', '151': 'think', '152': 'difficult', '153': 'translate', '154': 'between', '155': 'spanish', '156': 'portuguese', '157': 'big', '158': 'green', '159': 'strawberries.', '160': 'translating', '161': 'fun', '162': 'grapes.', '163': 'lemon.', '164': 'where', '165': '?', '166': 'dog', '167': 'why', '168': 'might', '169': 'go', '170': 'this', '171': 'drove', '172': 'shiny', '173': 'orange.', '174': 'pear.', '175': 'sharks', '176': 'monkey', '177': 'strawberry.', '178': 'how', '179': 'weather', '180': 'lion', '181': 'plans', '182': 'bear', '183': 'pears.', '184': 'apple.', '185': 'rabbit', '186': \"it's\", '187': 'chinese', '188': 'when', '189': 'eiffel', '190': 'tower', '191': 'did', '192': 'grocery', '193': 'store', '194': 'wanted', '195': 'fruit.', '196': 'does', '197': 'football', '198': 'field', '199': 'wants', '200': \"didn't\", '201': 'lime.', '202': 'snake', '203': 'snakes', '204': 'do', '205': 'easy', '206': 'thinks', '207': 'english', '208': 'french', '209': 'would', '210': \"aren't\", '211': 'cats', '212': 'rabbits', '213': 'has', '214': 'been', '215': 'limes.', '216': 'monkeys', '217': 'grape.', '218': 'lake', '219': 'bears', '220': 'school', '221': 'birds', '222': 'want', '223': \"isn't\", '224': 'lions', '225': 'am', '226': 'mice', '227': 'have', '228': '<str>'}\n"
     ]
    }
   ],
   "source": [
    "print(en_id2t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data preprocessing\n",
    "\n",
    "The first step in preprocessing the data is to transform the sentences into lists, where the list values are the words, creating a list of lists. The second step is to change the words with the respective IDs.\n",
    "\n",
    "The following function does these two steps:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(list, dict):\n",
    "    list = [dict[i] for i in list]\n",
    "    return list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this basic model the entries are arrays with the same size (the maximum number of words that the longest phrase in our data set has). For this reason we need to add values (in our case zeros) in the list until we have the desired length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_list(list, dict):\n",
    "    list = tokenize(list, dict)\n",
    "    size = len(dict)\n",
    "    out = []\n",
    "    \n",
    "    for i in list:\n",
    "        arr = [0.]*size\n",
    "        arr[i] = 1.\n",
    "        out.append(arr)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Create Trining, Validation and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step separates the phrases we have in the three datasets in a random way according to the proportion we choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_db = []\n",
    "te_db = []\n",
    "va_db = []\n",
    "\n",
    "tr_va_p = 0.7 \n",
    "tr_p = 0.7\n",
    "\n",
    "if fr_max_w > en_max_w:\n",
    "    ph_lon = fr_max_w\n",
    "else:\n",
    "    ph_lon = en_max_w\n",
    "    \n",
    "for (en,fr) in zip(english_sentences, french_sentences):\n",
    "    \n",
    "    en = tokenize(en.split(), en_t2id)\n",
    "    en = en + [0]*(ph_lon-len(en))\n",
    "    fr = tokenize(fr.split(), fr_t2id)\n",
    "    fr = fr + [0]*(ph_lon-len(fr))\n",
    "    \n",
    "    if random.random() < tr_va_p:\n",
    "        if random.random() < tr_p:\n",
    "            tr_db.append((torch.LongTensor(en), torch.LongTensor(fr)))\n",
    "        else:\n",
    "            va_db.append((torch.LongTensor(en), torch.LongTensor(fr)))\n",
    "    else:\n",
    "        te_db.append((torch.LongTensor(en), torch.LongTensor(fr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. THE RNN\n",
    "\n",
    "This model is created using a bidirectional LSTM, the layers we use in the model are:\n",
    "* Embeding Layers (nn.Embedding()): A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "* Long Sort Term Memory Layer (LSTM())\n",
    "* Full Conect Layers (Dense())\n",
    "* Drop Out Layer\n",
    "\n",
    "#### 2.1 The Architecture\n",
    "For this model the input is an integer value representing the word ID and 0 if it is not a word. The output is an array with a length equal to the French dictionary, the position with the highest value in the array is the word in the French dictionary. The next image show hot it work\n",
    "<img src='images/lstm1.png' width=50% height=50%/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (emb): Embedding(230, 250)\n",
      "  (LSTM1): LSTM(250, 250, batch_first=True, dropout=0.5, bidirectional=True)\n",
      "  (Dense1): Linear(in_features=500, out_features=1785, bias=True)\n",
      "  (Dense2): Linear(in_features=1785, out_features=357, bias=True)\n",
      "  (batch_norm1): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batch_norm2): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jandr\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, en_dic = len(en_t2id), fr_dic=len(fr_t2id), device='cuda'):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # Embeding Layer\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "        self.emb = nn.Embedding(en_dic+1, 250)            \n",
    "        \n",
    "        # Bidirectional LSTM Layer\n",
    "        # https://pytorch.org/docs/1.9.1/generated/torch.nn.LSTM.html\n",
    "        self.LSTM1 = nn.LSTM(250, 250, num_layers=1, batch_first=True, bidirectional=True, dropout=0.5)\n",
    "        \n",
    "        # Dense Layer\n",
    "        self.Dense1 = nn.Linear(2*250, fr_dic*5)\n",
    "        self.Dense2 = nn.Linear(fr_dic*5, fr_dic)\n",
    "        \n",
    "        # Batch Norm Layer\n",
    "        self.batch_norm1 = nn.BatchNorm1d(23)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(23)\n",
    "        \n",
    "        # Dropout Layer\n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.batch_size = x.shape[0]\n",
    "        self.hidden = ( torch.zeros(2, self.batch_size, 250).to(self.device), \n",
    "                       torch.zeros(2, self.batch_size, 250).to(self.device) )\n",
    "        \n",
    "        x = self.emb(x)\n",
    "        out, self.hidden = self.LSTM1(x, self.hidden)\n",
    "        out = F.relu(out) \n",
    "#         out = self.batch_norm1(out)\n",
    "        out = self.Dense1(out)\n",
    "        out = F.relu(out)\n",
    "#         out = self.batch_norm2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.Dense2(out)\n",
    "        \n",
    "        return(out)\n",
    "    \n",
    "print(RNN())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training and Test\n",
    "\n",
    "#### 3.1 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "epochs = 25\n",
    "device = 'cuda'\n",
    "#device = 'cpu'\n",
    "display_step = 100\n",
    "rnn = RNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "tr_ds = DataLoader(tr_db, batch_size=batch_size, shuffle=True)\n",
    "te_ds = DataLoader(te_db, batch_size=20, shuffle=False)\n",
    "va_ds = DataLoader(va_db, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Train the Model\n",
    "In the following code fragment we train the model, and after each epoch the loss value is calculated with the validation data set. The model with the best result on the validation data set is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88c3d334a23440a9692f3f276e221eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; training loss value: 0.21237486988306045; Validation loss best model: False\n",
      "Best Model => loss validation:  0.21003732483313248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41266acf004747a9be058269214801aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2; training loss value: 0.14779297553002835; Validation loss best model: 0.21003732483313248\n",
      "Best Model => loss validation:  0.16452382799899082\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc07ab0dba3499f907c20664dcbaf40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3; training loss value: 0.11665285008028149; Validation loss best model: 0.16452382799899082\n",
      "Best Model => loss validation:  0.12676450346873505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4b0e957f464a5ba16d801717a7f84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4; training loss value: 0.09843497492372989; Validation loss best model: 0.12676450346873505\n",
      "Best Model => loss validation:  0.12031215741710279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe0425a7e4a4c2186a0583c86a8b9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5; training loss value: 0.09286088523454965; Validation loss best model: 0.12031215741710279\n",
      "Best Model => loss validation:  0.10974649041865349\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33b1d9c2e9f413fb1cf5400ccc1bdbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6; training loss value: 0.07785409480333329; Validation loss best model: 0.10974649041865349\n",
      "Best Model => loss validation:  0.1033988685669168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f37dab57764f59b870be626452130f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7; training loss value: 0.07627421802841126; Validation loss best model: 0.1033988685669168\n",
      "Best Model => loss validation:  0.09643795218139099\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e112423f5c244328b4482f8d6aa3fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8; training loss value: 0.0740972476825118; Validation loss best model: 0.0964379521813909999\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dd5efd72fd48fb94f23f76704b3c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9; training loss value: 0.07607283541932702; Validation loss best model: 0.096437952181390999\n",
      "Best Model => loss validation:  0.09478478351614678\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd2e68f9c7a495c930656134aaa5c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10; training loss value: 0.06126931469887495; Validation loss best model: 0.094784783516146788\n",
      "Best Model => loss validation:  0.09312386090135134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44818135c3224053b8f20c83ac990fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11; training loss value: 0.05779385215602815; Validation loss best model: 0.093123860901351344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc39248b20942b297d88eac434e8967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12; training loss value: 0.05426952555309981; Validation loss best model: 0.093123860901351344\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f4998e404a4071bf7379eeb12e1329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13; training loss value: 0.049223089085426185; Validation loss best model: 0.09312386090135134\n",
      "Best Model => loss validation:  0.09190128907752491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c298e911c5461699e07f8dffec629a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14; training loss value: 0.051730382626410575; Validation loss best model: 0.09190128907752491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5dd3d65e6cd4bc3b1fb26aae9a85c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15; training loss value: 0.05414232852868736; Validation loss best model: 0.091901289077524911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72780c311e94591851316d629d2d497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16; training loss value: 0.04669352049240842; Validation loss best model: 0.091901289077524911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a8f8a42b034adc9ced15e8911b2bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17; training loss value: 0.04348451728001237; Validation loss best model: 0.091901289077524911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7040422c9752484e87416206c3a337b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18; training loss value: 0.039777481248602274; Validation loss best model: 0.09190128907752491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a4d1829318436f9d72340483f091dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19; training loss value: 0.041475646081380546; Validation loss best model: 0.09190128907752491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cd879e1b4849339278418c813d7472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20; training loss value: 0.03785127162700519; Validation loss best model: 0.091901289077524911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743c0885af4a4b47852a8eb4f56d9e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21; training loss value: 0.043598038689233364; Validation loss best model: 0.09190128907752491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c18830dc3d439baa400e28d168d346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22; training loss value: 0.039084252649918196; Validation loss best model: 0.09190128907752491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd21841a002e4788bd80235b09be090a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23; training loss value: 0.04275313026504591; Validation loss best model: 0.091901289077524911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2542b84d5d241d582c5b665c67d9e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24; training loss value: 0.03569226786959916; Validation loss best model: 0.091901289077524911\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e515f19c00ca48c6816320dbf53fd7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2703.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25; training loss value: 0.030855008186772465; Validation loss best model: 0.09190128907752491\n"
     ]
    }
   ],
   "source": [
    "h_loss = []\n",
    "h_loss_it = []\n",
    "val_loss = []\n",
    "val_loss_it = []\n",
    "avg_loss = 0\n",
    "count = 0\n",
    "T_it = 0\n",
    "best_model = False\n",
    "\n",
    "it = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for eng, fre in tqdm(tr_ds):\n",
    "        it += 1\n",
    "        T_it += 1\n",
    "        \n",
    "        eng = eng.to(device)\n",
    "        fre = fre.to(device)\n",
    "        \n",
    "        # clear all the gradients\n",
    "        optimizer.zero_grad()\n",
    "        pred = rnn(eng)\n",
    "        \n",
    "        loss = criterion(pred.view(-1, len(fr_t2id)), fre.view(-1)) \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += pred.shape[0]\n",
    "        avg_loss += loss.item() * pred.shape[0]\n",
    "        \n",
    "        if it%display_step == 0:\n",
    "            h_loss.append(avg_loss/count)\n",
    "            h_loss_it.append(T_it)\n",
    "            b = 'Epoch: '+str(epoch+1)+'; training loss value: '+str(avg_loss/count)+'; Validation loss best model: '+str(best_model)\n",
    "            print(b, end=\"\\r\")\n",
    "            it = 0\n",
    "            count = 0\n",
    "            avg_loss = 0\n",
    "            \n",
    "    loss_va = 0\n",
    "    count_va = 0\n",
    "    for eng, fre in va_ds:\n",
    "        \n",
    "        eng = eng.to(device)\n",
    "        fre = fre.to(device)\n",
    "        pred = rnn(eng)\n",
    "        loss = criterion(pred.view(-1, len(fr_t2id)), fre.view(-1)).item() \n",
    "        count_va += pred.shape[0]\n",
    "        loss_va += loss * pred.shape[0]\n",
    "        \n",
    "    \n",
    "    loss_va = loss_va/count_va\n",
    "    val_loss.append(loss_va)\n",
    "    val_loss_it.append(T_it)\n",
    "    \n",
    "    if best_model==False or loss_va < best_model :\n",
    "        print('Best Model => loss validation: ', loss_va)\n",
    "        best_model = loss_va\n",
    "        model_dir = 'models/'\n",
    "        model_name = 'En2Fr_tr_best_model_1.pkl'\n",
    "        torch.save(rnn.state_dict(), model_dir+model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21910eff880>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h_loss_it, h_loss, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21910fed5e0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss_it, val_loss, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Testing the model\n",
    "After training the model it is necessary to test it with the test data set. With this step we can determine if our model has an over-fit, and know what the final accuracy is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (emb): Embedding(230, 250)\n",
       "  (LSTM1): LSTM(250, 250, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (Dense1): Linear(in_features=500, out_features=1785, bias=True)\n",
       "  (Dense2): Linear(in_features=1785, out_features=357, bias=True)\n",
       "  (batch_norm1): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_norm2): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = RNN(device='cpu')\n",
    "path = 'models/En2Fr_tr_best_model_1.pt'\n",
    "rnn.load_state_dict(torch.load(path))\n",
    "rnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_va = 0\n",
    "count_va = 0\n",
    "for eng, fre in te_ds:\n",
    "\n",
    "    eng = eng.to('cpu')\n",
    "    fre = fre.to('cpu')\n",
    "    pred = rnn(eng)\n",
    "    loss = criterion(pred.view(-1, len(fr_t2id)), fre.view(-1)).item() \n",
    "    count_va += pred.shape[0]\n",
    "    loss_va += loss * pred.shape[0]\n",
    "\n",
    "\n",
    "loss_va = loss_va/count_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value with the Test Dataset is:  0.0796529366653519\n"
     ]
    }
   ],
   "source": [
    "print('The loss value with the Test Dataset is: ', loss_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has good accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:  il conduit une vieille voiture verte . \n",
      "Prediction:  il conduit une vieille automobile verte . \n",
      "======================================\n",
      "Expected:  new jersey est parfois froid en avril , mais il est généralement doux à l' automne . \n",
      "Prediction:  new jersey est parfois frisquet en avril , mais il est généralement doux à l' automne . \n",
      "======================================\n",
      "Expected:  la france est jamais occupée en mars , et il est parfois agréable en septembre . \n",
      "Prediction:  la france est jamais occupée en mars , et il est parfois agréable en septembre . \n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "for expected, prediction in zip(fre,pred.max(2)[1]):\n",
    "    exp = ''\n",
    "    predic = ''\n",
    "    for i in expected:\n",
    "        if i!=0:\n",
    "            exp += fr_id2t[str(i.item())] + ' '\n",
    "    for i in prediction:\n",
    "        if i!=0:\n",
    "            predic += fr_id2t[str(i.item())] + ' '\n",
    "    \n",
    "    print( 'Expected: ',exp )\n",
    "    print( 'Prediction: ', predic )\n",
    "    print('======================================')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these 3 examples we can see that the model has a tight prediction. In 2 cases the model does not predict the expected word, but predicts a word with a very similar meaning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
