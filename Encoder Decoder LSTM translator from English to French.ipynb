{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENCODER-DECODER RECURRENT NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I am going to design and develop Encoder-Decoder RNN  with Pytorch and CUDA. The goal is to create an English to French translator.\n",
    "\n",
    "To carry out this project I implemented the knowledge I gained in the Udacity Natural Language Processing Nanodegree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA\n",
    "This type of project is computationally expensive, for this reason I will use a Dataset created by Udacity that uses a short vocabulary. This way I will test the architecture with a much lower computational and time cost.\n",
    "\n",
    "### 1.1 Load Data\n",
    "The data is located in `data/small_vocab_en` and `data/small_vocab_fr`. The `small_vocab_en` file contains English sentences with their French translations in the `small_vocab_fr` file. Load the English and French data from these files from running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SET LOADED\n"
     ]
    }
   ],
   "source": [
    "# Load English data\n",
    "english_sentences = load_data('data/small_vocab_en')\n",
    "# Load French data\n",
    "french_sentences = load_data('data/small_vocab_fr')\n",
    "\n",
    "print('DATA SET LOADED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase in English:  china is usually pleasant during november , and it is never quiet in october .\n",
      "Phrase in French:  chine est généralement agréable en novembre , et il est jamais tranquille en octobre .\n"
     ]
    }
   ],
   "source": [
    "print('Phrase in English: ', english_sentences[20])\n",
    "print('Phrase in French: ', french_sentences[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create and apply a word counter\n",
    "The following function creates a dictionary with the word count, and return the number of words that have the longest phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def world_count(texts):\n",
    "    w_count = {}\n",
    "    max_w = 0\n",
    "    \n",
    "    for i in texts:\n",
    "        ws = i.split()\n",
    "        \n",
    "        for w in  ws:\n",
    "            if w not in w_count:\n",
    "                w_count[w] = 1\n",
    "            else:\n",
    "                w_count[w] += 1\n",
    "                \n",
    "        if len(ws)>max_w:\n",
    "            max_w = len(ws)\n",
    "            \n",
    "    return w_count, max_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of words in a english phrase:  17\n",
      "English vocablary size:  227\n",
      "Max number of words in a french phrase:  23\n",
      "French vocablary size:  355\n"
     ]
    }
   ],
   "source": [
    "en_w_count, en_max_w = world_count(english_sentences)\n",
    "print('Max number of words in a english phrase: ', en_max_w)\n",
    "print('English vocablary size: ', len(en_w_count))\n",
    "\n",
    "fr_w_count, fr_max_w = world_count(french_sentences)\n",
    "print('Max number of words in a french phrase: ', fr_max_w)\n",
    "print('French vocablary size: ', len(fr_w_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the word counter we can see that the dataset we are using was carefully created, it does not have a large number of words and all of them are repeated an acceptable number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================  English word counter  ==================== \n",
      " \n",
      " {'new': 12197, 'jersey': 11225, 'is': 205858, 'sometimes': 37746, 'quiet': 8693, 'during': 74933, 'autumn': 9004, ',': 140897, 'and': 59850, 'it': 75137, 'snowy': 8898, 'in': 75525, 'april': 8954, '.': 129039, 'the': 67628, 'united': 11270, 'states': 11270, 'usually': 37507, 'chilly': 8770, 'july': 8956, 'freezing': 8928, 'november': 8951, 'california': 11250, 'march': 9023, 'hot': 8639, 'june': 9133, 'mild': 8743, 'cold': 8878, 'september': 8958, 'your': 9734, 'least': 27564, 'liked': 13546, 'fruit': 27105, 'grape': 4703, 'but': 63987, 'my': 9700, 'apple': 4652, 'his': 9700, 'favorite': 27371, 'orange': 4651, 'paris': 11334, 'relaxing': 8696, 'december': 8945, 'busy': 8791, 'spring': 9102, 'never': 37500, 'our': 8932, 'lemon': 4652, 'january': 9090, 'warm': 8890, 'lime': 4680, 'her': 9700, 'banana': 4652, 'he': 10786, 'saw': 648, 'a': 1944, 'old': 972, 'yellow': 972, 'truck': 1944, 'india': 11277, 'rainy': 8761, 'that': 2712, 'cat': 192, 'was': 1867, 'most': 14934, 'loved': 13666, 'animal': 2304, 'dislikes': 7314, 'grapefruit': 10118, 'limes': 5554, 'lemons': 5533, 'february': 8942, 'china': 10953, 'pleasant': 8916, 'october': 8910, 'wonderful': 8808, 'nice': 8984, 'summer': 8948, 'france': 11170, 'may': 8995, 'grapes': 5525, 'mangoes.': 295, 'their': 8932, 'mango': 4652, 'pear': 4652, 'august': 8789, 'beautiful': 8915, 'apples': 5452, 'peaches': 5451, 'feared': 768, 'shark': 192, 'wet': 8726, 'dry': 8794, 'we': 2532, 'like': 4588, 'oranges': 5452, 'mangoes': 5549, 'they': 3222, 'pears': 5451, 'she': 10786, 'little': 1016, 'red': 972, 'winter': 9038, 'disliked': 648, 'rusty': 972, 'car': 1944, 'strawberries': 5452, 'i': 2664, 'strawberry': 4715, 'bananas.': 392, 'going': 666, 'to': 5166, 'next': 1666, 'plan': 714, 'visit': 1224, 'elephants': 64, 'were': 384, 'animals': 768, 'favorite.': 961, 'are': 870, 'likes': 7314, 'bananas': 5452, 'dislike': 4444, 'fall': 9134, 'driving': 1296, 'oranges.': 392, 'liked.': 500, 'peach': 4652, 'loved.': 500, 'drives': 648, 'blue': 972, 'you': 2414, 'bird': 192, 'grapefruit.': 574, 'horses': 64, 'mouse': 192, 'went': 378, 'last': 781, 'peaches.': 393, 'horse': 192, 'automobile': 1944, 'dogs': 64, 'white': 972, 'elephant': 192, 'lemons.': 311, 'mango.': 196, 'apples.': 392, 'banana.': 196, 'peach.': 196, 'black': 972, 'think': 240, 'difficult': 260, 'translate': 480, 'between': 540, 'spanish': 312, 'portuguese': 312, 'big': 1016, 'green': 972, 'strawberries.': 392, 'translating': 300, 'fun': 260, 'grapes.': 319, 'lemon.': 196, 'where': 12, '?': 811, 'dog': 192, 'why': 240, 'might': 378, 'go': 1386, 'this': 768, 'drove': 648, 'shiny': 972, 'orange.': 197, 'pear.': 196, 'sharks': 64, 'monkey': 192, 'strawberry.': 133, 'how': 67, 'weather': 33, 'lion': 192, 'plans': 476, 'bear': 192, 'pears.': 393, 'apple.': 196, 'rabbit': 192, \"it's\": 240, 'chinese': 312, 'when': 144, 'eiffel': 57, 'tower': 57, 'did': 204, 'grocery': 57, 'store': 57, 'wanted': 378, 'fruit.': 87, 'does': 24, 'football': 57, 'field': 57, 'wants': 252, \"didn't\": 60, 'lime.': 168, 'snake': 192, 'snakes': 64, 'do': 84, 'easy': 260, 'thinks': 360, 'english': 312, 'french': 312, 'would': 48, \"aren't\": 36, 'cats': 64, 'rabbits': 64, 'has': 24, 'been': 36, 'limes.': 290, 'monkeys': 64, 'grape.': 145, 'lake': 57, 'bears': 64, 'school': 57, 'birds': 64, 'want': 126, \"isn't\": 24, 'lions': 64, 'am': 24, 'mice': 64, 'have': 12}\n"
     ]
    }
   ],
   "source": [
    "print('======================  English word counter  ====================','\\n','\\n',en_w_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================  French word counter  ==================== \n",
      " \n",
      " {'new': 11047, 'jersey': 11052, 'est': 196809, 'parfois': 37746, 'calme': 7256, 'pendant': 10741, \"l'\": 32917, 'automne': 14727, ',': 123135, 'et': 59851, 'il': 84079, 'neigeux': 1867, 'en': 105768, 'avril': 8954, '.': 135619, 'les': 65255, 'états-unis': 11210, 'généralement': 31292, 'froid': 16794, 'juillet': 8956, 'gèle': 3622, 'habituellement': 6215, 'novembre': 8951, 'california': 3061, 'mars': 9023, 'chaud': 16405, 'juin': 9133, 'légère': 63, 'fait': 2916, 'septembre': 8958, 'votre': 9368, 'moins': 27557, 'aimé': 24842, 'fruit': 23626, 'le': 35306, 'raisin': 4852, 'mais': 63987, 'mon': 9403, 'la': 49861, 'pomme': 4848, 'son': 16496, 'préféré': 22886, \"l'orange\": 4848, 'paris': 11334, 'relaxant': 8458, 'décembre': 8945, 'occupé': 7782, 'au': 25738, 'printemps': 9100, 'jamais': 37215, 'chaude': 1124, 'notre': 8319, 'citron': 4848, 'janvier': 9090, 'chaux': 4848, 'des': 2435, 'fruits': 3566, 'banane': 4848, 'aimé.': 1010, 'a': 1356, 'vu': 645, 'un': 698, 'vieux': 325, 'camion': 1944, 'jaune': 972, 'inde': 11277, 'pluvieux': 7658, 'ce': 1465, 'chat': 192, 'était': 1198, 'animal': 2248, 'plus': 14934, \"n'aime\": 3131, 'pamplemousse': 10140, 'citrons': 11679, 'verts': 5835, 'californie': 8189, 'ne': 2715, 'février': 8942, 'gel': 4886, 'chine': 10936, 'agréable': 17751, 'octobre': 8911, 'merveilleux': 8704, 'doux': 8458, 'tranquille': 1437, 'à': 13870, \"l'automne\": 3411, 'été': 8999, 'france': 11170, 'mois': 14350, 'de': 15070, 'mai': 8995, 'frisquet': 834, 'déteste': 3743, 'raisins': 5780, 'mangues': 5774, 'leur': 7855, 'mangue': 4899, 'poire': 4848, 'août': 8789, 'beau': 6387, 'pommes': 5844, 'pêches': 5844, 'redouté': 576, 'que': 667, 'requin': 192, 'humide': 8446, \"d'\": 5100, 'sec': 7957, 'enneigée': 4008, 'nous': 2520, 'aimons': 1111, 'oranges': 5844, 'ils': 3185, 'aiment': 1116, 'poires': 5844, 'elle': 12056, 'petit': 324, 'rouge': 972, 'cher': 1308, 'aimée': 105, 'neige': 3016, 'trop': 173, 'monde': 173, 'hiver': 9038, 'sont': 1018, \"n'aimait\": 561, 'pas': 4495, 'une': 1278, 'voiture': 3510, 'rouillée': 486, 'fraises': 5844, 'cours': 1927, \"j'aime\": 966, 'fraise': 4848, 'bananes': 5844, 'va': 355, 'aux': 392, 'prochain': 1666, 'je': 1548, 'prévois': 233, 'visiter': 908, 'belle': 2726, 'éléphants': 64, 'étaient': 357, 'ses': 402, 'animaux': 768, 'redoutés': 190, 'vont': 168, 'aime': 8870, 'préférée': 770, \"n'aiment\": 1111, 'i': 150, 'comme': 259, 'conduit': 1706, 'pêche': 4848, 'préféré.': 419, 'nouvelle': 648, 'bleue': 504, 'vous': 2517, 'aimez': 1053, 'cet': 286, 'oiseau': 128, 'pamplemousses': 552, 'pleut': 562, 'magnifique': 104, 'favori': 3857, 'vos': 225, 'aimés': 237, 'chevaux': 64, \"n'aimez\": 1094, \"n'aimons\": 97, 'souris': 256, 'détestons': 1001, 'allé': 187, 'dernier': 757, 'conduisait': 673, 'petite': 615, 'glaciales': 307, 'cheval': 192, 'vieille': 647, 'chiens': 64, 'préférés': 383, 'blanche': 579, 'occupée': 836, 'nos': 613, \"l'éléphant\": 64, 'nouveau': 502, 'noire': 602, 'pluies': 367, 'pense': 540, \"qu'il\": 393, 'difficile': 260, 'traduire': 501, 'entre': 540, 'espagnol': 312, 'portugais': 312, 'bleu': 468, 'rouillé': 454, 'aimait': 707, 'grande': 459, 'verte': 628, 'traduction': 277, 'amusant': 260, 'cette': 1239, 'vert': 344, 'grand': 81, 'blanc': 393, 'volant': 165, 'gros': 258, 'où': 12, 'États-unis': 57, '?': 811, 'chien': 192, 'leurs': 1072, 'pourquoi': 240, '-': 328, \"l'automobile\": 100, 'pourrait': 252, 'se': 461, 'rendre': 350, 'prévoyons': 232, 'maillot': 173, 'grosse': 185, 'brillant': 587, 'prévoient': 75, 'mouillée': 7, 'lui': 70, 'détendre': 111, 'automobile': 278, 'pourraient': 126, 'aller': 1180, 'mes': 297, 'sèche': 837, \"l'oiseau\": 64, 'pluie': 174, 'requins': 64, 'noir': 370, 'singe': 192, 'détestait': 87, 'comment': 67, 'temps': 33, 'dans': 12, 'lion': 192, 'prévoit': 75, 'ours': 192, 'porcelaine': 17, 'clémentes': 200, 'plaît': 13, 'proches': 20, 'brillante': 385, 'lapin': 192, \"l'ours\": 64, 'chinois': 312, 'quand': 144, 'tour': 57, 'eiffel': 57, 'est-ce': 12, 'allons': 45, \"l'épicerie\": 57, 'voulait': 252, 'cépage': 60, 't': 18, 'terrain': 57, 'football': 57, 'du': 39, 'veut': 252, 'éléphant': 128, 'gelé': 94, 'bien': 77, 'enneigé': 7, 'gelés': 5, 'serpent': 192, 'allés': 150, 'allée': 150, 'envisage': 360, 'peu': 41, 'mouillé': 273, 'serpents': 64, 'pensez': 60, 'facile': 260, 'anglais': 312, 'français': 312, 'voulez': 12, 'grandes': 16, 'avez': 162, 'aimeraient': 12, 'allez': 45, 'chats': 64, 'lapins': 64, 'visite': 68, 'ont': 194, 'intention': 206, \"n'est\": 47, '-elle': 24, 'dernière': 24, 'voulaient': 126, 'singes': 64, 'êtes-vous': 24, '-ce': 95, \"qu'elle\": 26, 'vers': 76, 'lac': 57, 'pousse': 41, 'détestez': 17, 'manguiers': 19, 'grands': 9, '-il': 36, \"l'école\": 57, '-ils': 26, \"l'animal\": 56, 'at': 32, 'oiseaux': 64, 'ressort': 2, 'petits': 10, \"n'a\": 12, 'veulent': 126, 'rouille': 32, 'frais': 20, 'limes': 9, 'lions': 64, 'douce': 14, 'envisagent': 9, 'petites': 26, 'vais': 24, 'durant': 14, \"c'est\": 17, 'congélation': 14, 'allions': 1, 'voudrait': 24, 'détend': 2, 'trouvé': 1, 'préférées': 16, 'conduite': 6, 'grosses': 8, 'bénigne': 8, 'avons': 19, 'sur': 28, 'redoutée': 2, 'etats-unis': 3, 'moindres': 7, 'aiment-ils': 10, \"n'êtes\": 3, 'vit': 3, 'as-tu': 1, 'qui': 2, 'faire': 1, 'traduis': 2, 'favoris': 1, 'souvent': 1, 'es-tu': 1, 'apprécié': 2, 'moteur': 1, 'tout': 4}\n"
     ]
    }
   ],
   "source": [
    "print('======================  French word counter  ====================','\\n','\\n',fr_w_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create and apply a word counter\n",
    "\n",
    "Using the word counter I create a function that returns two Dictionary objects.  These dictionaries contain all the words that exceed a minimum number of repetitions in the dataset, and their assigned ID. One of the dictionaries has as key the word and as value the ID, and the other dictionary inverts the key and the value of the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dic(t_count, min_t=1, start=False, end=False, nan=False):\n",
    "    id2t = {}\n",
    "    t2id = {}\n",
    "    id = 0\n",
    "    \n",
    "    if nan == True:                 # There is no word\n",
    "        id2t[str(id)] = '<nan>'\n",
    "        t2id['<nan>'] = id\n",
    "        id += 1\n",
    "    \n",
    "    if start == True:               # start value of the phrase\n",
    "        id2t[str(id)] = '<start>'\n",
    "        t2id['<start>'] = id\n",
    "        id += 1\n",
    "        \n",
    "    if end == True:                 # end value of the phrase\n",
    "        id2t[str(id)] = '<end>'\n",
    "        t2id['<end>'] = id\n",
    "        id += 1\n",
    "        \n",
    "    for i in t_count:               \n",
    "        if t_count[i] >= min_t:    # The word is repeated more than the minimum chosen\n",
    "            \n",
    "            t2id[i] = id\n",
    "            id2t[str(id)] = i\n",
    "            \n",
    "            id += 1\n",
    "            \n",
    "    # add to the dictionary a token and an Id to the tokens that are not in the dictionary\n",
    "    t2id['<str>'] = id            \n",
    "    id2t[str(id)] = '<str>'\n",
    "\n",
    "    return id2t, t2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_id2t, en_t2id = create_dic(en_w_count, min_t=1, start=True, end=True, nan=True)\n",
    "fr_id2t, fr_t2id = create_dic(fr_w_count, min_t=1, start=True, end=True, nan=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**English dictionary whose key is the word and the value is the ID**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<nan>': 0, '<start>': 1, '<end>': 2, 'new': 3, 'jersey': 4, 'is': 5, 'sometimes': 6, 'quiet': 7, 'during': 8, 'autumn': 9, ',': 10, 'and': 11, 'it': 12, 'snowy': 13, 'in': 14, 'april': 15, '.': 16, 'the': 17, 'united': 18, 'states': 19, 'usually': 20, 'chilly': 21, 'july': 22, 'freezing': 23, 'november': 24, 'california': 25, 'march': 26, 'hot': 27, 'june': 28, 'mild': 29, 'cold': 30, 'september': 31, 'your': 32, 'least': 33, 'liked': 34, 'fruit': 35, 'grape': 36, 'but': 37, 'my': 38, 'apple': 39, 'his': 40, 'favorite': 41, 'orange': 42, 'paris': 43, 'relaxing': 44, 'december': 45, 'busy': 46, 'spring': 47, 'never': 48, 'our': 49, 'lemon': 50, 'january': 51, 'warm': 52, 'lime': 53, 'her': 54, 'banana': 55, 'he': 56, 'saw': 57, 'a': 58, 'old': 59, 'yellow': 60, 'truck': 61, 'india': 62, 'rainy': 63, 'that': 64, 'cat': 65, 'was': 66, 'most': 67, 'loved': 68, 'animal': 69, 'dislikes': 70, 'grapefruit': 71, 'limes': 72, 'lemons': 73, 'february': 74, 'china': 75, 'pleasant': 76, 'october': 77, 'wonderful': 78, 'nice': 79, 'summer': 80, 'france': 81, 'may': 82, 'grapes': 83, 'mangoes.': 84, 'their': 85, 'mango': 86, 'pear': 87, 'august': 88, 'beautiful': 89, 'apples': 90, 'peaches': 91, 'feared': 92, 'shark': 93, 'wet': 94, 'dry': 95, 'we': 96, 'like': 97, 'oranges': 98, 'mangoes': 99, 'they': 100, 'pears': 101, 'she': 102, 'little': 103, 'red': 104, 'winter': 105, 'disliked': 106, 'rusty': 107, 'car': 108, 'strawberries': 109, 'i': 110, 'strawberry': 111, 'bananas.': 112, 'going': 113, 'to': 114, 'next': 115, 'plan': 116, 'visit': 117, 'elephants': 118, 'were': 119, 'animals': 120, 'favorite.': 121, 'are': 122, 'likes': 123, 'bananas': 124, 'dislike': 125, 'fall': 126, 'driving': 127, 'oranges.': 128, 'liked.': 129, 'peach': 130, 'loved.': 131, 'drives': 132, 'blue': 133, 'you': 134, 'bird': 135, 'grapefruit.': 136, 'horses': 137, 'mouse': 138, 'went': 139, 'last': 140, 'peaches.': 141, 'horse': 142, 'automobile': 143, 'dogs': 144, 'white': 145, 'elephant': 146, 'lemons.': 147, 'mango.': 148, 'apples.': 149, 'banana.': 150, 'peach.': 151, 'black': 152, 'think': 153, 'difficult': 154, 'translate': 155, 'between': 156, 'spanish': 157, 'portuguese': 158, 'big': 159, 'green': 160, 'strawberries.': 161, 'translating': 162, 'fun': 163, 'grapes.': 164, 'lemon.': 165, 'where': 166, '?': 167, 'dog': 168, 'why': 169, 'might': 170, 'go': 171, 'this': 172, 'drove': 173, 'shiny': 174, 'orange.': 175, 'pear.': 176, 'sharks': 177, 'monkey': 178, 'strawberry.': 179, 'how': 180, 'weather': 181, 'lion': 182, 'plans': 183, 'bear': 184, 'pears.': 185, 'apple.': 186, 'rabbit': 187, \"it's\": 188, 'chinese': 189, 'when': 190, 'eiffel': 191, 'tower': 192, 'did': 193, 'grocery': 194, 'store': 195, 'wanted': 196, 'fruit.': 197, 'does': 198, 'football': 199, 'field': 200, 'wants': 201, \"didn't\": 202, 'lime.': 203, 'snake': 204, 'snakes': 205, 'do': 206, 'easy': 207, 'thinks': 208, 'english': 209, 'french': 210, 'would': 211, \"aren't\": 212, 'cats': 213, 'rabbits': 214, 'has': 215, 'been': 216, 'limes.': 217, 'monkeys': 218, 'grape.': 219, 'lake': 220, 'bears': 221, 'school': 222, 'birds': 223, 'want': 224, \"isn't\": 225, 'lions': 226, 'am': 227, 'mice': 228, 'have': 229, '<str>': 230}\n"
     ]
    }
   ],
   "source": [
    "print(en_t2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': '<nan>', '1': '<start>', '2': '<end>', '3': 'new', '4': 'jersey', '5': 'is', '6': 'sometimes', '7': 'quiet', '8': 'during', '9': 'autumn', '10': ',', '11': 'and', '12': 'it', '13': 'snowy', '14': 'in', '15': 'april', '16': '.', '17': 'the', '18': 'united', '19': 'states', '20': 'usually', '21': 'chilly', '22': 'july', '23': 'freezing', '24': 'november', '25': 'california', '26': 'march', '27': 'hot', '28': 'june', '29': 'mild', '30': 'cold', '31': 'september', '32': 'your', '33': 'least', '34': 'liked', '35': 'fruit', '36': 'grape', '37': 'but', '38': 'my', '39': 'apple', '40': 'his', '41': 'favorite', '42': 'orange', '43': 'paris', '44': 'relaxing', '45': 'december', '46': 'busy', '47': 'spring', '48': 'never', '49': 'our', '50': 'lemon', '51': 'january', '52': 'warm', '53': 'lime', '54': 'her', '55': 'banana', '56': 'he', '57': 'saw', '58': 'a', '59': 'old', '60': 'yellow', '61': 'truck', '62': 'india', '63': 'rainy', '64': 'that', '65': 'cat', '66': 'was', '67': 'most', '68': 'loved', '69': 'animal', '70': 'dislikes', '71': 'grapefruit', '72': 'limes', '73': 'lemons', '74': 'february', '75': 'china', '76': 'pleasant', '77': 'october', '78': 'wonderful', '79': 'nice', '80': 'summer', '81': 'france', '82': 'may', '83': 'grapes', '84': 'mangoes.', '85': 'their', '86': 'mango', '87': 'pear', '88': 'august', '89': 'beautiful', '90': 'apples', '91': 'peaches', '92': 'feared', '93': 'shark', '94': 'wet', '95': 'dry', '96': 'we', '97': 'like', '98': 'oranges', '99': 'mangoes', '100': 'they', '101': 'pears', '102': 'she', '103': 'little', '104': 'red', '105': 'winter', '106': 'disliked', '107': 'rusty', '108': 'car', '109': 'strawberries', '110': 'i', '111': 'strawberry', '112': 'bananas.', '113': 'going', '114': 'to', '115': 'next', '116': 'plan', '117': 'visit', '118': 'elephants', '119': 'were', '120': 'animals', '121': 'favorite.', '122': 'are', '123': 'likes', '124': 'bananas', '125': 'dislike', '126': 'fall', '127': 'driving', '128': 'oranges.', '129': 'liked.', '130': 'peach', '131': 'loved.', '132': 'drives', '133': 'blue', '134': 'you', '135': 'bird', '136': 'grapefruit.', '137': 'horses', '138': 'mouse', '139': 'went', '140': 'last', '141': 'peaches.', '142': 'horse', '143': 'automobile', '144': 'dogs', '145': 'white', '146': 'elephant', '147': 'lemons.', '148': 'mango.', '149': 'apples.', '150': 'banana.', '151': 'peach.', '152': 'black', '153': 'think', '154': 'difficult', '155': 'translate', '156': 'between', '157': 'spanish', '158': 'portuguese', '159': 'big', '160': 'green', '161': 'strawberries.', '162': 'translating', '163': 'fun', '164': 'grapes.', '165': 'lemon.', '166': 'where', '167': '?', '168': 'dog', '169': 'why', '170': 'might', '171': 'go', '172': 'this', '173': 'drove', '174': 'shiny', '175': 'orange.', '176': 'pear.', '177': 'sharks', '178': 'monkey', '179': 'strawberry.', '180': 'how', '181': 'weather', '182': 'lion', '183': 'plans', '184': 'bear', '185': 'pears.', '186': 'apple.', '187': 'rabbit', '188': \"it's\", '189': 'chinese', '190': 'when', '191': 'eiffel', '192': 'tower', '193': 'did', '194': 'grocery', '195': 'store', '196': 'wanted', '197': 'fruit.', '198': 'does', '199': 'football', '200': 'field', '201': 'wants', '202': \"didn't\", '203': 'lime.', '204': 'snake', '205': 'snakes', '206': 'do', '207': 'easy', '208': 'thinks', '209': 'english', '210': 'french', '211': 'would', '212': \"aren't\", '213': 'cats', '214': 'rabbits', '215': 'has', '216': 'been', '217': 'limes.', '218': 'monkeys', '219': 'grape.', '220': 'lake', '221': 'bears', '222': 'school', '223': 'birds', '224': 'want', '225': \"isn't\", '226': 'lions', '227': 'am', '228': 'mice', '229': 'have', '230': '<str>'}\n"
     ]
    }
   ],
   "source": [
    "print(en_id2t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data preprocessing\n",
    "\n",
    "The first step in preprocessing the data is to transform the sentences into lists, where the list values are the words, creating a list of lists. The second step is to change the words with the respective IDs.\n",
    "\n",
    "The following function does these two steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(list, dict):\n",
    "    list = [dict[i] for i in list]\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_list(list, dict):\n",
    "    list = tokenize(list, dict)\n",
    "    size = len(dict)\n",
    "    out = []\n",
    "    \n",
    "    for i in list:\n",
    "        arr = [0.]*size\n",
    "        arr[i] = 1.\n",
    "        out.append(arr)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Create Training, Validation and Test Datasets\n",
    "The next step separates the phrases we have in the three datasets in a random way according to the proportion we choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_db = []\n",
    "te_db = []\n",
    "va_db = []\n",
    "\n",
    "tr_va_p = 0.7 \n",
    "tr_p = 0.7\n",
    "\n",
    "if fr_max_w > en_max_w:\n",
    "    ph_lon = fr_max_w + 2\n",
    "else:\n",
    "    ph_lon = en_max_w + 2\n",
    "    \n",
    "for (en,fr) in zip(english_sentences, french_sentences):\n",
    "    \n",
    "    en = [en_t2id['<start>']] + tokenize(en.split(), en_t2id) + [en_t2id['<end>']]   # creta a list with the words id values \n",
    "    en = en + [0]*(ph_lon-len(en))\n",
    "    fr = [fr_t2id['<start>']] + tokenize(fr.split(), fr_t2id) + [fr_t2id['<end>']]\n",
    "    fr = fr + [0]*(ph_lon-len(fr))\n",
    "    \n",
    "    if random.random() < tr_va_p:\n",
    "        if random.random() < tr_p:\n",
    "            tr_db.append((torch.LongTensor(en), torch.LongTensor(fr)))\n",
    "        else:\n",
    "            va_db.append((torch.LongTensor(en), torch.LongTensor(fr)))\n",
    "    else:\n",
    "        te_db.append((torch.LongTensor(en), torch.LongTensor(fr)))\n",
    "#     if random.random() < tr_va_p:\n",
    "#         if random.random() < tr_p:\n",
    "#             tr_db.append((en, fr))\n",
    "#         else:\n",
    "#             va_db.append((en, fr))\n",
    "#     else:\n",
    "#         te_db.append((en, fr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples:\n",
      "tensor([ 1, 25,  5, 20,  7,  8, 26, 10, 11, 12,  5, 20, 27, 14, 28, 16,  2,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0])\n",
      "tensor([ 1, 43,  5, 44,  8, 45, 10, 37, 12,  5, 20, 21, 14, 22, 16,  2,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0])\n",
      "tensor([ 1,  3,  4,  5, 46,  8, 47, 10, 11, 12,  5, 48, 27, 14, 26, 16,  2,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0])\n",
      "tensor([ 1, 49, 33, 34, 35,  5, 17, 50, 10, 37, 38, 33, 34,  5, 17, 36, 16,  2,\n",
      "         0,  0,  0,  0,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "print('Some examples:')\n",
    "for i in range(4):\n",
    "    print(te_db[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples:\n",
      "tensor([ 1, 26,  5, 20,  7, 15, 27, 11, 12, 13,  5, 20, 28, 15, 29, 17,  2,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0])\n",
      "tensor([ 1, 46,  5, 47, 15, 48, 11, 39, 13,  5, 20, 21, 15, 22, 17,  2,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0])\n",
      "tensor([ 1,  3,  4,  5, 49, 50, 51, 11, 12, 13,  5, 52, 53, 15, 27, 17,  2,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0])\n",
      "tensor([ 1, 54, 36,  5, 34, 35, 37, 55, 11, 39, 40, 34, 35,  5, 37, 38, 17,  2,\n",
      "         0,  0,  0,  0,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "print('Some examples:')\n",
    "for i in range(4):\n",
    "    print(te_db[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 mean that the phrase is starting (*start*), and 2 mean that it is the end of the phrase (*end*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. THE RNN\n",
    "\n",
    "This model is created using two LSTM models, the Encoder and the Decoder. The layers we use in the model are:\n",
    "* Embeding Layers (nn.Embedding()): A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "* Long Sort Term Memory Layer (LSTM())\n",
    "* Full Conect Layers (Dense())\n",
    "* Drop Out Layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The Architecture\n",
    "\n",
    "#### 2.1.1 Encoder\n",
    "The encoder is the part of the neural network that \"reads\" the text and returns a matrix with the encoded information, to perform this step I am using a Bidirectional LSTM. The output matrix with the encoded information is obtained after inserting in a Dense NN the outputs of the first and last words. \n",
    "<img src='images/encoder_bd.png' width=50% height=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Decoder\n",
    "The decoder NN recive the characteristics of the text to translate, encoded in a array and using tha sequence to sequence architecture. The encoder output is the first input.\n",
    "<img src='images/decoder.png' width=50% height=50%/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder_Decoder(\n",
      "  (emb1): Embedding(232, 200)\n",
      "  (emb2): Embedding(360, 250)\n",
      "  (LSTM1): LSTM(200, 200, batch_first=True, bidirectional=True)\n",
      "  (LSTM2): LSTM(250, 250, num_layers=2, batch_first=True)\n",
      "  (Dense1): Linear(in_features=800, out_features=250, bias=True)\n",
      "  (Dense2): Linear(in_features=250, out_features=1795, bias=True)\n",
      "  (Dense3): Linear(in_features=1795, out_features=359, bias=True)\n",
      "  (ELU1): ELU(alpha=1.0)\n",
      "  (ELU2): ELU(alpha=1.0)\n",
      "  (ELU3): ELU(alpha=1.0)\n",
      "  (relu1): ReLU()\n",
      "  (dropout1): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder_Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, en_dic = len(en_t2id), fr_dic=len(fr_t2id), device='cuda'): #, decod_trainer):\n",
    "        super(Encoder_Decoder, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "#         self.decod_trainer = decod_trainer\n",
    "        \n",
    "        # Embeding Layer\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "        self.emb1 = nn.Embedding(en_dic+1, 200)\n",
    "        self.emb2 = nn.Embedding(fr_dic+1, 250) \n",
    "        \n",
    "        # Bidirectional LSTM Layer\n",
    "        # https://pytorch.org/docs/1.9.1/generated/torch.nn.LSTM.html\n",
    "        self.LSTM1 = nn.LSTM(200, 200, num_layers=1, dropout=0.0, batch_first=True, bidirectional=True)\n",
    "        self.LSTM2 = nn.LSTM(250, 250, num_layers=2, dropout=0.0, batch_first=True)\n",
    "        \n",
    "        # Dense Layer\n",
    "        self.Dense1 = nn.Linear(200*4, 250)\n",
    "        self.Dense2 = nn.Linear(250, fr_dic*5)\n",
    "        self.Dense3 = nn.Linear(fr_dic*5, fr_dic)\n",
    "        \n",
    "        #Activation Function\n",
    "        self.ELU1 = nn.ELU()\n",
    "        self.ELU2 = nn.ELU()\n",
    "        self.ELU3 = nn.ELU()\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        #Drop Out layer\n",
    "        self.dropout1 = nn.Dropout(p=0.3)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        output = []\n",
    "        for ph, ph_dec in zip(x, y):\n",
    "            \n",
    "            #### ENCODER\n",
    "            self.hidden1 = ( torch.zeros(2,1, 200).to(self.device), \n",
    "                       torch.zeros(2,1, 200).to(self.device) )\n",
    "            \n",
    "            \n",
    "            for i in range(ph.size()[0]):\n",
    "                if ph[i] == 0:\n",
    "                    ph = ph[:i]\n",
    "                    break\n",
    "            out = ph.view((1,ph.size()[0]))\n",
    "            out = self.emb1(out)\n",
    "            out, self.hidden1 = self.LSTM1(out, self.hidden1)\n",
    "            #out = self.ELU1(out)\n",
    "            out = torch.cat((out[0][0],out[0][-1]), 0)\n",
    "            out = self.Dense1(out)\n",
    "            out = self.ELU2(out)\n",
    "            out = self.dropout1(out)\n",
    "            \n",
    "            #### Decoder\n",
    "            self.hidden2 = ( torch.zeros(2,1, 250).to(self.device), \n",
    "                       torch.zeros(2,1, 250).to(self.device) )\n",
    "            \n",
    "            for i in range(ph_dec.size()[0]):\n",
    "                if ph_dec[i] == 2:\n",
    "                    ph_dec = ph_dec[1:i]\n",
    "                    break\n",
    "            out = out.view((1,1,out.size()[0]))\n",
    "            #out, self.hidden2 = self.LSTM2(out, self.hidden2)\n",
    "            dec_inp = ph_dec.view((1,ph_dec.size()[0]))\n",
    "            dec_inp = self.emb2(dec_inp)\n",
    "            out = torch.cat((out, dec_inp), 1)\n",
    "            out, self.hidden2 = self.LSTM2(out, self.hidden2)\n",
    "            #out = self.ELU3(out)\n",
    "            out = self.Dense2(out)\n",
    "            out = self.relu1(out)\n",
    "            out = self.dropout1(out)\n",
    "            out = self.Dense3(out)\n",
    "            \n",
    "            \n",
    "            output.append(out)\n",
    "        return output\n",
    "    \n",
    "    def predict(self, x):\n",
    "        end = False\n",
    "        ph_tr = []\n",
    "        output = []\n",
    "        it = 0\n",
    "        for ph in x:\n",
    "            \n",
    "            #### ENCODER\n",
    "            self.hidden1 = ( torch.zeros(2,1, 200).to(self.device), \n",
    "                       torch.zeros(2,1, 200).to(self.device) )\n",
    "            \n",
    "            \n",
    "            for i in range(ph.size()[0]):\n",
    "                if ph[i] == 2:\n",
    "                    ph = ph[:i+1]\n",
    "                    break\n",
    "            out = ph.view((1,ph.size()[0]))\n",
    "            out = self.emb1(out)\n",
    "            out, self.hidden1 = self.LSTM1(out, self.hidden1)\n",
    "            #out = self.ELU1(out)\n",
    "            out = torch.cat((out[0][0],out[0][-1]), 0)\n",
    "            out = self.Dense1(out)\n",
    "            out = self.ELU2(out)\n",
    "            \n",
    "            #### Decoder\n",
    "            self.hidden2 = ( torch.zeros(2,1, 250).to(self.device), \n",
    "                       torch.zeros(2,1, 250).to(self.device) )\n",
    "            \n",
    "            out = out.view((1,1,out.size()[0]))\n",
    "            \n",
    "            while end == False and it<=25:\n",
    "                if it != 0:\n",
    "                    out = self.emb2(out)\n",
    "                out, self.hidden2 = self.LSTM2(out, self.hidden2)\n",
    "                out = self.Dense2(out)\n",
    "                out = self.relu1(out)\n",
    "                out = self.Dense3(out)\n",
    "                out = out.max(2)[1]\n",
    "                ph_tr.append(out.item())\n",
    "                \n",
    "                if out == 2:\n",
    "                    end = True\n",
    "                it += 1\n",
    "            output.append(ph)\n",
    "            ph = []\n",
    "        return output\n",
    "  \n",
    "            \n",
    "print(Encoder_Decoder())        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training and Test\n",
    "\n",
    "#### 3.1 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "epochs = 15\n",
    "device = 'cuda'\n",
    "#device = 'cpu'\n",
    "display_step = 100\n",
    "rnn = Encoder_Decoder(device=device).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.0001, betas=(0.85, 0.999))\n",
    "\n",
    "tr_ds = DataLoader(tr_db, batch_size=batch_size, shuffle=True)\n",
    "te_ds = DataLoader(te_db, batch_size=50, shuffle=True)\n",
    "va_ds = DataLoader(va_db, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Loss Function\n",
    "In this case all sentences are not the same size, and it is not possible to introduce a tensor with arrays at different sizes in the loss function and ac. For this reason I need to customize both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(prediction, expected, optimizer, dict_len):\n",
    "    loss = False\n",
    "    counter = 0 \n",
    "    for pred, exp in zip(prediction, expected):\n",
    "        \n",
    "        for i in range(exp.size()[0]):\n",
    "            if exp[i] == 2:\n",
    "                exp = exp[1:i+1]\n",
    "                counter += i-1\n",
    "                break\n",
    "                \n",
    "        if loss != False:\n",
    "            loss += criterion( pred.view(-1,dict_len), exp.view(-1))*(i-1)\n",
    "        else:\n",
    "            loss = criterion( pred.view(-1,dict_len), exp.view(-1))*(i-1)\n",
    "            \n",
    "#         if exp.size() != pred.size():\n",
    "#             print('ERROR: Dimensioality error between the prediction and the expected data')\n",
    "        \n",
    "    loss = loss/counter\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_function(prediction, expected):\n",
    "    \n",
    "    acc = 0\n",
    "    counter = 0 \n",
    "    for pred, exp in zip(prediction, expected):\n",
    "        pred = pred.detach().to('cpu')\n",
    "        exp = exp.detach().to('cpu')\n",
    "        \n",
    "        for i in range(exp.size()[0]):\n",
    "            if exp[i] == 2:\n",
    "                exp = exp[1:i+1]\n",
    "                counter += i-1\n",
    "                break\n",
    "                \n",
    "#         print(pred[0].max(1)[1].size())\n",
    "#         print(exp.size())\n",
    "        pred = pred[0].max(1)[1].numpy()\n",
    "        exp = exp.numpy()\n",
    "        \n",
    "        acc += accuracy_score(pred, exp)*(i-1)\n",
    "    \n",
    "    return acc/counter\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train the model\n",
    "In the next step the model is trained with the training data set using the hyperparameters we have selected. After each epoch the model is tested with the validation data set, if the loss value is less than the previous best result, we save this version as the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2354a39f4544d769147507cf7b385a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1; training loss value: 0.6132933557033539; Best model=> Validation loss: False; Validation acc: False\n",
      "Best Model => loss validation:  0.6265814946212962 ; acc validation:  0.768164401139402\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9499ec6f95ea4a97b464831801bd6473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2; training loss value: 0.4434470671415329; Best model=> Validation loss: 0.6265814946212962; Validation acc: 0.7681644011394022\n",
      "Best Model => loss validation:  0.44235023212398095 ; acc validation:  0.8455012966046944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28a835e1fc046b098504084f600fb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3; training loss value: 0.35588482037186625; Best model=> Validation loss: 0.44235023212398095; Validation acc: 0.8455012966046944\n",
      "Best Model => loss validation:  0.33751138535088554 ; acc validation:  0.88604931634759\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b63dcead774d8588ae568072fc8061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4; training loss value: 0.27745657816529273; Best model=> Validation loss: 0.33751138535088554; Validation acc: 0.88604931634759\n",
      "Best Model => loss validation:  0.27776925884618675 ; acc validation:  0.9054142578897215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86d599189e349d7b013ede32933c007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5; training loss value: 0.1946743605285883; Best model=> Validation loss: 0.27776925884618675; Validation acc: 0.90541425788972155\n",
      "Best Model => loss validation:  0.19662542600086905 ; acc validation:  0.9302729718064578\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0dc856bb09644de886aa18124497279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6; training loss value: 0.16715320134535433; Best model=> Validation loss: 0.19662542600086905; Validation acc: 0.9302729718064578\n",
      "Best Model => loss validation:  0.17697651549726787 ; acc validation:  0.9360799296087565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86d881e963e4796bd6231ae55cdaed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7; training loss value: 0.13899426974356174; Best model=> Validation loss: 0.17697651549726787; Validation acc: 0.9360799296087565\n",
      "Best Model => loss validation:  0.15794619557187387 ; acc validation:  0.9421426921647847\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d72d15dacf4b7495a7429e86c8b843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8; training loss value: 0.13194973060395568; Best model=> Validation loss: 0.15794619557187387; Validation acc: 0.9421426921647847\n",
      "Best Model => loss validation:  0.14270631222158087 ; acc validation:  0.9474997522712202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e81c2683f474f9ea1656d0fca5ccb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9; training loss value: 0.0927473863447085; Best model=> Validation loss: 0.14270631222158087; Validation acc: 0.94749975227122022\n",
      "Best Model => loss validation:  0.10500772321489914 ; acc validation:  0.9623837557032412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2a3ac2af784c2390ae7512344d20f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10; training loss value: 0.07791909822262824; Best model=> Validation loss: 0.10500772321489914; Validation acc: 0.9623837557032412\n",
      "Best Model => loss validation:  0.08615895384479531 ; acc validation:  0.9693836429699965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fa657a2d124fbd80f12f70644728a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11; training loss value: 0.05425824481062591; Best model=> Validation loss: 0.08615895384479531; Validation acc: 0.96938364296999655\n",
      "Best Model => loss validation:  0.06231644563519169 ; acc validation:  0.9786978956180474\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42400a70d1e14e5288ad5fcce144d8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12; training loss value: 0.05945955938543193; Best model=> Validation loss: 0.06231644563519169; Validation acc: 0.97869789561804744\n",
      "Best Model => loss validation:  0.05210672176799092 ; acc validation:  0.9828236056181731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eceb814b6fda450ca794a8a79169c4d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13; training loss value: 0.03818253285484388; Best model=> Validation loss: 0.05210672176799092; Validation acc: 0.98282360561817311\n",
      "Best Model => loss validation:  0.04837001527731633 ; acc validation:  0.9841457765520424\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ee8b848a304972a3bcdfdc61d98654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14; training loss value: 0.030808705514064057; Best model=> Validation loss: 0.04837001527731633; Validation acc: 0.9841457765520424\n",
      "Best Model => loss validation:  0.04200089417020067 ; acc validation:  0.9865284609578638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0b28c36b8243af8306960201741a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=13542.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15; training loss value: 0.026999501095851884; Best model=> Validation loss: 0.04200089417020067; Validation acc: 0.9865284609578638\n"
     ]
    }
   ],
   "source": [
    "h_loss = []\n",
    "h_loss_it = []\n",
    "val_loss = []\n",
    "val_loss_it = []\n",
    "val_acc = []\n",
    "\n",
    "avg_loss = 0\n",
    "count = 0\n",
    "T_it = 0\n",
    "best_model_loss = False\n",
    "best_model_acc = False\n",
    "\n",
    "it = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for eng, fre in tqdm(tr_ds):\n",
    "        it += 1\n",
    "        T_it += 1\n",
    "        \n",
    "        eng = eng.to(device)\n",
    "        fre = fre.to(device)\n",
    "        \n",
    "        # clear all the gradients\n",
    "        optimizer.zero_grad()\n",
    "        pred = rnn(eng, fre)\n",
    "        #print(pred.size())\n",
    "        #print(acc(pred, fre))\n",
    "        loss = loss_function(pred, fre, criterion, len(fr_t2id))\n",
    "        #loss = criterion(pred.view(-1, len(fr_t2id)), fre.view(-1))\n",
    "        #print(loss)\n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += fre.shape[0]\n",
    "        avg_loss += loss.item() * fre.shape[0]\n",
    "        \n",
    "        if it%display_step == 0:\n",
    "            h_loss.append(avg_loss/count)\n",
    "            h_loss_it.append(T_it)\n",
    "            b = 'Epoch: '+str(epoch+1)+'; training loss value: '+str(avg_loss/count)+'; Best model=> Validation loss: '+str(best_model_loss) + '; Validation acc: '+str(best_model_acc)\n",
    "            print(b, end=\"\\r\")\n",
    "            it = 0\n",
    "            count = 0\n",
    "            avg_loss = 0\n",
    "            \n",
    "    loss_va = 0\n",
    "    acc_va = 0\n",
    "    count_va = 0\n",
    "    for eng, fre in va_ds:\n",
    "        \n",
    "        eng = eng.to(device)\n",
    "        fre = fre.to(device)\n",
    "        pred = rnn(eng, fre)\n",
    "        loss = loss_function(pred, fre, criterion, len(fr_t2id)).item() \n",
    "        acc = acc_function(pred, fre)\n",
    "        count_va += fre.shape[0]\n",
    "        loss_va += loss * fre.shape[0]\n",
    "        acc_va += acc * fre.shape[0]\n",
    "        \n",
    "        \n",
    "    \n",
    "    loss_va = loss_va/count_va\n",
    "    acc_va = acc_va/count_va\n",
    "    val_loss.append(loss_va)\n",
    "    val_loss_it.append(T_it)\n",
    "    val_acc.append(acc_va)\n",
    "    \n",
    "    if best_model_loss==False or loss_va < best_model_loss :\n",
    "        print('Best Model => loss validation: ', loss_va, '; acc validation: ', acc_va)\n",
    "        best_model_loss = loss_va\n",
    "        best_model_acc = acc_va\n",
    "        model_dir = 'models/'\n",
    "        model_name = 'En2Fr_tr_best_model_enc_dec1.pkl'\n",
    "        torch.save(rnn.state_dict(), model_dir+model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VALIDATION RESUTS**\n",
    "\n",
    "The evolution of the loss function and acc each epoch is showing that the selected hyperparameters made the model stable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2001735abe0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(h_loss_it, h_loss, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data obtained during training, the first observation is that the computational cost is higher than that of a bidirectional RNN such as the model trained on the other Notewook, which was to be expected comparing the two architectures.  On the other hand, this model has a lower loss value and the acc obtained (0.986) using the Validation data is very satisfactory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x200172cf430>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlvUlEQVR4nO3deXxU5b3H8c8vCRBQCBgQlUVA2QUU4woC9nqVRcUiWHGB2nq5WGxBxIJ1t7VVRItULSLF/RJ36xXUa6kiopbNEAFFqaggCIiygxDy3D+eGWcyZJnIJGcy832/Xuc1M+eczPxyEr48ec5znmPOOUREpObLCLoAERFJDAW6iEiKUKCLiKQIBbqISIpQoIuIpIisoD64cePGrlWrVkF9vIhIjbR48eJvnHNNStsWWKC3atWKRYsWBfXxIiI1kpl9UdY2dbmIiKQIBbqISIqoMNDNbIaZbTSzZWVsNzObYmarzKzQzLonvkwREalIPC30R4G+5WzvB7QNLSOAvx58WSIiUlkVBrpz7m3g23J2GQg87rz3gYZmdmSiChQRkfgkog+9GbAm6vXa0LoDmNkIM1tkZos2bdqUgI8WEZGwRAS6lbKu1CkcnXPTnHN5zrm8Jk1KHUYpIiI/UiLGoa8FWkS9bg6sS8D7iohUzDnYvx/27vXLvn2R52Ut8e6zf3/JzzKr3POytp1+OvzkJ4n5/qMkItBfBq42s3zgFGCrc259At5XRJJFURHs3Am7dpW+lLWttPVFRT4ow4/h5ce+Li6uuu87OowTee+I8eODCXQzmwn0ARqb2VrgFqAWgHNuKjAb6A+sAnYBVyS8ShFJnF27YMOG8peNG2HbtkgI79tX+c+pUwfq1Su51K0LtWpBZqbfnpkZWbKySn8e7+vatSteatWKf59atSAjjl7p6KCPDf2ytsW24hOkwkB3zg2tYLsDRiWsIhGpHOdgx46KQzq87NhR+vs0bAhNm/qlSxf/OjqMDznkwIAub31mZnUeheCU191SzQKby0VEYuzfD1u2wHffwbff+sfoJXZd+PXmzb4VHcsMcnMjIX3SSZHnscvhh/sWs9RoCnSRqrR1K6xaBZ9+Cl98EQnh0sJ527by36tePWjUyC+HHQatW0P37iVDO3pp0sR3RUja0E9b5GBt2+YDOxzc0c9jr7eoU6dkKDdrBscdF3kd3lbaa7WgpQIKdJF4bNsWCenY4N64seS+zZpB27ZwwQVw7LH+edu2vkV9yCGBlC/pQYEu6ev772H7dh/W27dHli1b4LPPSgZ3aaF97LFw/vk+rMPBfcwxvmtEJAAKdKlZ9u71/dLhJTqMY4O5tHXRrysainfUUT6kzzsv0so+9lgf2mppSxJSoEv12bOnZBhXZtm2zT/u2VPx55hB/fp+adAg8vzwww9cV9p+DRrA0UcrtKXGUaBLxfbu9YEaXsIBW97z0rbt3VvxZ9WvDzk5PlRzcqBxY98izskpfYkN4vr1fZdHwOOBRYKgQBc/jvmdd2DePCgo8H3I0WEcT6s4K6tkEDdo4PuZO3Xyz8Pry1vq10+fi1FEqoACPR2tWePDO7wsX+7X16kD3brBEUdAu3Ylw7m85w0aQHa2WsUiAVOgpzrnYOXKkgH++ed+W/360KMHXHIJnHGGv5IwOzvQckXkx1Ogp5qiIli6tGSAhy9uOfxwH9xjxvjHbt3UxSGSQhToNd2ePbBgQSS8333XD8kDaNUK+vXz4X3GGb4bRd0iIilLgV6TFBf7i10KCuCDD/yJzAULIqNHOneGyy6LBHjz5oGWKyLVS4GerHbtgg8/9OFdUOC7UQoL/Q0DwI8q6d4dfvMbH949evhJmkQkbSnQg+YcfP11JLTDAf7JJ5EJ8XNyfH/3L38Jxx/vl06dNFmTiJSgQK9ORUU+qKNb3QUFJecJadXKB/bQoT7Ejz/eX7Wovm8RqYACvSrt2AHPP+/7ugsKYNmyyEU6tWv7aVMHDIi0urt29XeJERH5ERToieYcLFwI06dDfr4fcZKb6wN71KhIq7tDB3/PQhGRBFGgJ8q338KTT/og//BDP5/IRRfBlVfC6aery0REqpwC/WAUF8Nbb/kQf+EFP7/2SSfB1Klw8cX+ZKaISDVRoP8Y69bBo4/C3/7mb4TQsCGMGOFHoXTrFnR1IpKmFOjxKiqC2bN9a3zWLN86P/NM+P3v4ac/hbp1g65QRNKcAr0iq1bBjBm+Rb5+vZ+JcPx4+MUv/N1rRESShAK9NLt3+z7x6dN9H3lGhh9eeOWV0L+/v0pTRCTJKJmiLV3qQ/zJJ/1NHtq0gTvugOHD/c0aRESSmAId/JDDK6+EF1/0F/xceKF/3aePb52LiNQACvT33vNDDNevhz/8AUaO1CRXIlIjpW+gFxfDPffA734HLVrA/Pl+DLmISA2VnoH+zTe+X3z2bN+9Mn265lARkRov/QJ93jw/k+GmTfDAA3DVVbosX0RSQvqc8Ssu9iNW+vTxFwG9/z786lcKcxFJGenRQt+wAS6/HN54w7fOH3rI3/FeRCSFxNVCN7O+ZrbSzFaZ2YRStueY2f+a2VIzW25mVyS+1B/pn//009XOmwcPPwxPPaUwF5GUVGGgm1km8ADQD+gEDDWzTjG7jQJWOOe6AX2Ae8ysdoJrrZz9++GWW+Css/wJzwUL/NhydbGISIqKp4V+MrDKOfeZc24vkA8MjNnHAfXNzIBDgW+BooRWWhnr1vkgv/1239WycCF06RJYOSIi1SGeQG8GrIl6vTa0Ltr9QEdgHfAhMNo5Vxz7RmY2wswWmdmiTZs2/ciSK/D6676LZcECP6HWY4/BoYdWzWeJiCSReAK9tD4KF/P6HKAAOAo4HrjfzBoc8EXOTXPO5Tnn8po0aVLJUitQVATXXw99+0LTpr5VPnx4Yj9DRCSJxRPoa4EWUa+b41vi0a4AXnDeKmA10CExJcZhzRo/HPHOO30/+b/+BZ1iu/lFRFJbPIG+EGhrZq1DJzovBl6O2edL4D8AzKwp0B74LJGFlmnWLN/FsnSpH8Hy8MP+fp4iImmmwkB3zhUBVwOvAx8BzzjnlpvZSDMbGdrt98DpZvYhMAcY75z7pqqKBmDvXhg3Ds49F1q2hMWL4ZJLqvQjRUSSWVwXFjnnZgOzY9ZNjXq+Djg7saWV4/PP/QyJ//qXv9rznnsgO7vaPl5EJBnVvCtF33gDLrrIX8r/zDMwZEjQFYmIJIWaF+gtW/o+87/9zd9RSEREgJoY6O3bw5tvBl2FiEjSSZ/ZFkVEUpwCXUQkRSjQRURShAJdRCRFKNBFRFKEAl1EJEUo0EVEUoQCXUQkRSjQRURShAJdRCRFKNBFRFKEAl1EJEUo0EVEUoQCXUQkRSjQRURShAJdRCRFKNBFRFKEAl1EJEUo0EVEUoQCXUQkRSjQRURShAJdRCRFKNBFRFKEAl1EJEUo0EVEUoQCXUQkRdS4QHcO3nkn6CpERJJPjQv0GTPgjDPg7beDrkREJLnUuEAfOhSaN4exY6G4OOhqRESSR40L9Hr14E9/gsWL4amngq5GRCR5xBXoZtbXzFaa2Sozm1DGPn3MrMDMlpvZ3MSWWdIll8BJJ8H118POnVX5SSIiNUeFgW5mmcADQD+gEzDUzDrF7NMQeBA43znXGRiS+FIjMjLg3nvhq6/gnnuq8pNERGqOeFroJwOrnHOfOef2AvnAwJh9LgFecM59CeCc25jYMg/UsycMHgx33QXr1lX1p4mIJL94Ar0ZsCbq9drQumjtgEZm9paZLTazYaW9kZmNMLNFZrZo06ZNP67iKHfdBUVFcMMNB/1WIiI1XjyBbqWsczGvs4ATgQHAOcBNZtbugC9ybppzLs85l9ekSZNKFxurTRsYPRoeewyWLDnotxMRqdHiCfS1QIuo182B2E6OtcBrzrmdzrlvgLeBbokpsXw33AC5uXDttf6iIxGRdBVPoC8E2ppZazOrDVwMvByzz9+BM8wsy8zqAacAHyW21NLl5MDtt8Nbb8Hf/14dnygikpwqDHTnXBFwNfA6PqSfcc4tN7ORZjYytM9HwGtAIbAAmO6cW1Z1ZZf0X/8FHTvCddfB3r3V9akiIsnFXED9FHl5eW7RokUJe79XX4X+/eHPf4YxYxL2tiIiScXMFjvn8krbVuOuFC1Lv35wzjlw222weXPQ1YiIVL+UCXSASZNg2zbfpy4ikm5SKtCPO873pz/4IKxcGXQ1IiLVK6UCHXzrvG5df4JURCSdpFygH364H5v+v/8Lc+YEXY2ISPVJuUAHf/Voq1b+YqP9+4OuRkSkeqRkoGdn+3leli6FRx8NuhoRkeqRkoEOMGQInHYa3HgjbN8edDUiIlUvZQPdzF9k9PXXMHFi0NWIiFS9lA10gFNO8Xc3mjQJvvwy6GpERKpWSgc6+PuPAvzud8HWISJS1VI+0Fu2hLFj/Q2lFywIuhoRkaqT8oEOMGECNG3qg11zpotIqkqLQK9fH/7wB5g/H557LuhqRESqRloEOsAVV0CXLjB+POzZE3Q1IiKJlzaBnpkJ994Lq1fDlClBVyMiknhpE+gAZ50F554Ld9wBGzcGXY2ISGKlVaAD3H037NwJt94adCUiIomVdoHeoQNcdRU89BAsXx50NSIiiZN2gQ6+dd6gAYwbF3QlIiKJk5aBnpsLN90Er73mFxGRVJCWgQ4wahQcc4yfM72oKOhqREQOXtoGep06/gTpihUwfXrQ1YiIHLy0DXSACy6AXr3g5pth69agqxEROThpHehm/mKjb76BP/4x6GpERA5OWgc6wIknwrBhMHmyv4pURKSmSvtAB3/laGamZmMUkZpNgQ40a+bHpr/0Evz61wp1EamZsoIuIFlcd52f3+Wee3xrffJk38cuIlJTKNBDzPwwxuJif3Pp8E2mFeoiUlMo0KOY+RZ6cTHcd59vqU+apFAXkZpBgR4j3DIvLvZDGjMyYOJEhbqIJD8FeinMfAu9uNi30DMy4M47FeoiktziGuViZn3NbKWZrTKzCeXsd5KZ7TezwYkrMRhm8Je/+Kl2J06EG27Q6BcRSW4VttDNLBN4APhPYC2w0Mxeds6tKGW/u4DXq6LQIJjB/ff7lvqf/uRb6r//vVrqIpKc4ulyORlY5Zz7DMDM8oGBwIqY/X4NPA+clNAKA5aRAQ8+CPv3Ry5Auu22oKsSETlQPIHeDFgT9XotcEr0DmbWDPgp8BPKCXQzGwGMAGjZsmVlaw1MRoa/w1FxMdx+u399yy1BVyUiUlI8gV5aB0Nsb/JkYLxzbr+V0x/hnJsGTAPIy8urUT3SGRnw8MM+1G+91b++6aagqxIRiYgn0NcCLaJeNwfWxeyTB+SHwrwx0N/MipxzLyWiyGSRkeHnTnfOT7mbkeFPloqIJIN4An0h0NbMWgNfARcDl0Tv4JxrHX5uZo8Cr6RamIdlZsLf/uZb6jfe6F9PKHPcj4hI9akw0J1zRWZ2NX70SiYwwzm33MxGhrZPreIak05mJjzyiD9Rev31vqX+298GXZWIpLu4Lixyzs0GZsesKzXInXM/P/iykl9mJjz2mO9+GT/eh/q4cUFXJSLpTFeKHoSsLHj8cd/9ct11PuSvuSboqkQkXSnQD1JWFjz5pA/1sWN9S3306KCrEpF0pEBPgKwseOopH+pjxvhQ//Wvg65KRNKN7liUILVqwcyZ8NOfwm9+Aw88EHRFIpJuFOgJVKsW5OfDwIFw9dXw178GXZGIpBMFeoLVrg3PPAPnnQe/+pWfMkBEpDoo0KtA7drw7LNw7rkwciT88Y+wd2/QVYlIqlOgV5E6deC552DIED89wHHHwSuvaE51Eak6CvQqVKeO736ZPduPfDnvPOjbF1bETjwsIpIACvRq0K8ffPghTJ4MCxZA165+WOO33wZdmYikEgV6NalVy19w9OmnMGKEv2nGscf6OyIVFQVdnYikAgV6NWvc2Id5QQF07+5b6t26wf/9X9CViUhNp0APSJcu8MYb8NJL8P33cM45vo/9k0+CrkxEaioFeoDM/EVIy5fDXXfB3Ll+NMy4cbB1a9DViUhNo0BPAnXq+PnUP/kEhg2De++Ftm1h2jQ/57qISDwU6EnkiCP8Le4WLYL27eG//xtOPNG33EVEKqJAT0Ldu8Pbb8PTT8N330GfPjB4MKxeHXRlIpLMFOhJygwuugg+/hhuvx1efRU6dvRXne7YEXR1IpKMFOhJrm5duOkm378+ZIifF6ZdO3/7u+LioKsTkWSiQK8hmjWDJ56A996Dli3h5z/3I2S2bAm6MhFJFgr0GubUU+Hdd2HKFHjtNcjLg6VLg65KRJKBAr0GCt/ibu5c2L0bTjvNt95FJL0p0Guw00+HJUvg5JP9+PVRozTvukg6U6DXcE2bwj/+4a8uffBB6N0b1q4NuioRCYICPQVkZcHdd/u7JC1b5sexv/lm0FWJSHVToKeQwYP9fOu5uXDWWT7kdYckkfShQE8xHTv6UB80yM8PM3gwbNsWdFUiUh0U6Cmofn1/67tJk+Dvf/cnTXXbO5HUp0BPUWZw7bX+hOl33/lQf+aZoKsSkaqkQE9xffr4oY1du8LPfgZjx8K+fUFXJSJVQYGeBpo1g7fegquvhj//2Z8w/frroKsSkURToKeJ2rXhL3/xV5QuXOiHNs6fH3RVIpJICvQ0c9ll8P77UK+e746ZMkVDG0VSRVyBbmZ9zWylma0yswmlbL/UzApDy7tm1i3xpUqidO3q74rUrx+MHg2XXgo7dwZdlYgcrAoD3cwygQeAfkAnYKiZdYrZbTXQ2znXFfg9MC3RhUpiNWwIL70Ef/gD5Of7WRw//TToqkTkYMTTQj8ZWOWc+8w5txfIBwZG7+Cce9c5913o5ftA88SWKVUhI8PfAem112DdOj8V77PPaoIvkZoqK459mgFrol6vBU4pZ/9fAq+WtsHMRgAjAFq2bBlniVLVzj7bD20cPNjf9q5WLejcGY4/3i8nnADdukFOTtCVikh54gl0K2VdqafRzOxMfKD3LG27c24aoe6YvLw8nYpLIkcfDfPmwcsv+3AvKIDZs+HRRyP7tGkTCfhw2Ddr5i9iEpHgxRPoa4EWUa+bA+tidzKzrsB0oJ9zbnNiypPqlJ3tW+gXXeRfO+fHq3/wgQ/48OMLL0S+pnHjkiF/wgn+nqeZmdVfv0i6iyfQFwJtzaw18BVwMXBJ9A5m1hJ4AbjcOfdJwquUQJjBkUf6pX//yPrt2/1t76JD/r77In3vdetCly4lQ75LFz9UUkSqjrk4BiGbWX9gMpAJzHDO3WFmIwGcc1PNbDpwIfBF6EuKnHN55b1nXl6eW7Ro0cHULklk3z746KOSIV9QELmJtRm0bev74qOX5s3VZSNSGWa2uKx8jSvQq0Jpgb5v3z7Wrl3Lnj17Aqkp1WVnZ9O8eXNq1apVLZ/nHHzxhQ/4pUsjy+rVkX0aNTow5Dt18t0/InKgGhPoq1evpn79+uTm5mJqtiWUc47Nmzezfft2WrduHWgt27ZBYWEk4AsL4cMPYdcuvz0zE9q3PzDojzhCrXmR8gI9nj70arNnzx5atWqlMK8CZkZubi6bNm0KuhQaNICePf0Stn8//PvfJVvy77wDM2dG9mnS5MCQb98e6tSp/u9BJBklVaADCvMqlMzHNjPTj45p1w6GDIms//bbSGs+/Hj//fD99357Rga0bBn52rZtI49HH+3vtyqSLvTrLkntsMP8JGJ9+kTWFRXBJ5/4cF+50j//9FN4/PGSt9urVcuPnY8O+vDzo47y/xmIpBIFeoxDDz2UHTt2VNn79+nTh+uvv55zzjnnh3WTJ0/mk08+4cEHHyzzayZNmkReXrkDh9JGVpY/cdopZkYh52DjRh/u4ZAPP77xBkSfa69XD4499sBWfbt2fmx9Ev8xI1ImBXo1Gzp0KPn5+SUCPT8/n7vvvjvAqlKDGTRt6peeMdcqFxfD2rUHhn1hoZ+krKgosm+jRnDuuXD55fCTn+giKak5kjbQx4zx45gT6fjjYfLkyn9dQUEBI0eOZNeuXRxzzDHMmDGDRo0aMWXKFKZOnUpWVhadOnUiPz+fuXPnMnr0aMD3Wb/99tvUr1//h/caPHgwN954I99//z116tTh888/Z926dfTs2ZOrrrqKhQsXsnv3bgYPHsxtt912QC3Rf0E899xzvPLKKzz66KNs2rSJkSNH8uWXXwK+1d+jR4/Kf7MpKtzX3rIl/Md/lNy2b58fXhkO+oICePFFfzOQo46CSy7x4d61ayCli8RNvYhxGDZsGHfddReFhYV06dLlh6C98847+eCDDygsLGTq1KkATJo0iQceeICCggLmzZtH3bp1S7xXbm4uJ598Mq+99hrgW+c/+9nPMDPuuOMOFi1aRGFhIXPnzqWwsDDuGkePHs0111zDwoULef7557nyyisT9N2nvlq1fPdL//5+fvhHHvFTHjz7rJ+BcvLkyKiaSZP8zJQiyShpW+g/piVdFbZu3cqWLVvo3bs3AMOHD2dIaBhG165dufTSS7ngggu44IILAOjRowdjx47l0ksvZdCgQTRvfuBMwuFul4EDB5Kfn8+MGTMAeOaZZ5g2bRpFRUWsX7+eFStW0DXOZuE//vEPVqxY8cPrbdu2sX379hJ/HUj8srP97JODB8M338DTT8OTT8J118Fvf+tb+ZdfDoMGwaGHBl2tiKcW+kGYNWsWo0aNYvHixZx44okUFRUxYcIEpk+fzu7duzn11FP5+OOPD/i6Cy64gDlz5rBkyRJ2795N9+7dWb16NZMmTWLOnDkUFhYyYMCAUq+YjR56GL29uLiY9957j4KCAgoKCvjqq68U5gnSuDGMGgXvvee7ZW66yY+ZHz7c99dfdhm8/nrJfniRICjQK5CTk0OjRo2YN28eAE888QS9e/emuLiYNWvWcOaZZzJx4kS2bNnCjh07+Pe//02XLl0YP348eXl5pQb6oYceSp8+ffjFL37B0KFDAd+iPuSQQ8jJyWHDhg28+mqpU8rTtGlTPvroI4qLi3nxxRd/WH/22Wdz//33//C6INEnIATwI2Fuu80H+jvv+Fb67NnQty+0aAHXXuv74HWfVglC0na5BGXXrl0luknGjh3LY4899sNJ0TZt2vDII4+wf/9+LrvsMrZu3YpzjmuuuYaGDRty00038eabb5KZmUmnTp3o169fqZ8zdOhQBg0aRH5+PgDdunXjhBNOoHPnzrRp06bME5p33nkn5557Li1atOC444774QTplClTGDVqFF27dqWoqIhevXr90K8viWcGPXr45b77YNYsfxL1L3+Be+/1Nwi5/HJ/v9ZSet1EqkRSzeXy0Ucf0bFjx0DqSRc6xlVr82Z/MvWJJ+Ddd33wn3mmD/cLLwT1gsnBKm8uF3W5iCRQbi6MHAnz58OqVXDLLX5I5BVX+Kteu3Txfe4TJ/p7ua5fr+4ZSRx1uYhUkWOO8YF+883w/vvwyit+uoK334annors17ixHxLZtWvksVMnTTomladAF6liZnDaaX4J+/ZbP2Vw9KRjf/1rZHqCzEzo0OHAoD/ySE1LIGVToIsE4LDDoHdvv4Tt3++7aaJD/p134H/+J7JP48Y+2KNDvnNntebFU6CLJInwjT3at4/cqBvgu+9KtuYLC+Ghh2D3br+9dm1/RWuPHnD66X45/PBgvgcJlgJdJMk1agS9evklLPqGIAsX+pOw990H4Tne2rb1wR4eWtmhg6YLTgf6EZfixRdfxMxKXBS0YMECevXqRfv27enQoQNXXnklu0L3THv11VfJy8ujY8eOdOjQgXHjxgVVuqSJ8A1BhgzxI2bmz4etW30XzcSJ/qTqrFkwYoTvkmncGAYMgD/+EebOjdzuT1KLWuilmDlzJj179iQ/P59bb72VDRs2MGTIEPLz8znttNNwzvH888+zfft2PvvsM66++mpmzZpFhw4dKCoqYtq0aUF/C5KGsrMjLfLrrvPDIT/91I+Hnz/fL7Nn+32zsuCEEyL7n366n1lSarbkvbAooPlzd+zYQfv27XnzzTc5//zz+fjjj7n55psBuP322w/Yf9iwYT9cxl8T6MKi9LZ5sx9CGQ74BQsiI2tatSoZ8B066GRrMqoxN4lOBi+99BJ9+/alXbt2HHbYYSxZsoRly5YxfPjwUvdftmwZ1157bTVXKfLj5Ob6rpcBA/zrvXt9uykc8HPmlBwj36iRHyp51FH+MXYJrz/kkEC+HYmRvIEe0Py5M2fOZMyYMQBcfPHFzIy+7bxIiqldG04+2S/XXOO7aT7/3HfTrF7tr2QNL3Pn+nni9+498H3q1y877KOXnByNo69KyRvoAdi8eTP//Oc/WbZsGWbG/v37MTOGDx/O4sWLGThw4AFf07lzZxYvXky3bt0CqFgkscygdWu/lMY5f1FUOOTXrSsZ+uvX+1E369ZFhlVGy872rfl69aBu3chysK8POQQaNvT/YWRnp+9/Ggr0KM899xzDhg3joYce+mFd7969Oeussxg2bBgDBgzglFNOAeDJJ5/krLPO4rrrrmPQoEH07NmTdu3aUVxczOTJkxk7dmxQ34ZIlTHz3Ta5uXDccWXv5xxs23Zg2H/9Nezc6cN+924/2ib8fMuWA9ft3l35eeZr146Ee8OGBz4vb1tOjv9ro6b+h6BAjzJz5kwmTJhQYt2FF15Ifn4++fn5jBs3jo0bN5KRkUGvXr0YNGgQRxxxBJMnT2bo0KHs2rULM2NAuINSJE2Z+XDMyfEnVw/Gvn0lAz56CYf/zp1+2OaWLZHH8LJ1q79BePh1aX85RMvIiIR8drZfFx47EvtY3rby9hk5EsaPr+SBiEPyjnKRKqFjLOlu797ywz/6+e7dkdZ6WY/lbStrnwEDSl4NXBka5SIiElK7NjRp4pdUoytFRURSRNIFelBdQOlAx1YktSVVoGdnZ7N582YFTxVwzrF582ayw2d5RCTlJFUfevPmzVm7di2bNm0KupSUlJ2dXeIG2CKSWuIKdDPrC9wHZALTnXN3xmy30Pb+wC7g5865JZUtplatWrQu64oGEREpV4VdLmaWCTwA9AM6AUPNrFPMbv2AtqFlBPDXBNcpIiIViKcP/WRglXPuM+fcXiAfiL0GfiDwuPPeBxqa2ZEJrlVERMoRT6A3A9ZEvV4bWlfZfTCzEWa2yMwWqZ9cRCSx4ulDL21Wg9hhKPHsg3NuGjANwMw2mdkXcXx+VWsMfBN0EeVQfQdH9R2cZK8Pkr/GRNd3dFkb4gn0tUCLqNfNgXU/Yp8SnHNJcZ2WmS0q6zLaZKD6Do7qOzjJXh8kf43VWV88XS4LgbZm1trMagMXAy/H7PMyMMy8U4Gtzrn1Ca5VRETKUWEL3TlXZGZXA6/jhy3OcM4tN7ORoe1Tgdn4IYur8MMWr6i6kkVEpDRxjUN3zs3Gh3b0uqlRzx0wKrGlVZtkv6Oz6js4qu/gJHt9kPw1Vlt9gU2fKyIiiZVUc7mIiMiPp0AXEUkVzrkav+CHTL4JfAQsB0aH1t8KfAUUhJb+UV9zPf4k7krgnKj1JwIfhrZNIdItVQd4OrT+X0CrStb4eeh9C4BFoXWHAW8An4YeGwVRH9A+6hgVANuAMUEeP2AGsBFYFrWuWo4XMDz0GZ8CwytR393Ax0Ah8CLQMLS+FbA76jhODai+avl5xlNfOTU+HVXf50BBEMeQsjMlaX4HSz2mlQmlZF2AI4Huoef1gU/w887cCowrZf9OwNLQAW0N/BvIDG1bAJyGv1jqVaBfaP2vwr9E+KGbT1eyxs+BxjHrJgITQs8nAHcFVV9UTZnA1/iLFwI7fkAvoDsl/7FX+fHC/4P9LPTYKPS8UZz1nQ1khZ7fFVVfq+j9Yt6nOuur8p9nvPWVVWPM9nuAm4M4hpSdKUnzO1jqsfgx/+iTfQH+DvxnOb/A1wPXR71+PXTAjwQ+jlo/FHgoep/Q8yz8lV9WiZo+58BAXwkcGfULtDKo+qLe82xgfuh5oMePmH/E1XG8ovcJbXsIGBpPfTHbfgo8Vd5+1V1fdfw8K1NfBcfG8NOJtA3yGEbtE86UpPodjF1Srg/dzFoBJ+D/hAG42swKzWyGmTUKrStr7plmoeex60t8jXOuCNgK5FaiNAf8n5ktNrMRoXVNXegCrNDj4QHWF3YxMDPqdbIcP6ie4xXXvERx+AW+NRbW2sw+MLO5ZnZGVA3VXV9V/zwTdfzOADY45z6NWhfIMYzJlKT+HUypQDezQ4HngTHOuW34aXyPAY4H1uP/hIOy554pb06auOarKUcP51x3/FTDo8ysVzn7BlEfoSuBzweeDa1KpuNXnkTWk4jjeANQBDwVWrUeaOmcOwEYC/yPmTUIoL7q+Hkm6uc8lJINi0COYSmZUpakOIYpE+hmVgt/4J9yzr0A4Jzb4Jzb75wrBh7GTwUMZc89szb0PHZ9ia8xsywgB/g23vqcc+tCjxvxJ8xOBjaEpxkOPW4Mqr6QfsAS59yGUK1Jc/xCquN4VXpeomhmNhw4F7jUhf5eds5975zbHHq+GN+/2q6666umn+dBHb+o9xuEP2EYrr3aj2FpmUKy/w7G0y+T7Av+f7THgcmx/WtRz68B8kPPO1PyBMZnRE5gLAROJXICo39o/ShKnsB4phL1HQLUj3r+LtAXPyoi+gTLxCDqi6ozH7giWY4fB/YBV/nxwp+IWo0/GdUo9PywOOvrC6wAmsTs1ySqnjb4kSaHBVBflf88K1NfaTVGHce5QR5Dys6UpPodPOB4VvYffTIuQE/8nySFRA3JAp7ADxcqxE8gFv0LfQP+f/mVhM46h9bnActC2+4nMsQoG98VsQp/1rpNJeprE/phL8UPgbohtD4XmIMfmjQn+odWnfWFvr4esBnIiVoX2PHD/7m9HtiHb7H8srqOF77/e1VouaIS9a3C932GfwfD/1gvDP3clwJLgPMCqq9afp7x1FdWjaH1jwIjY/at1mNI2ZmSNL+DpS269F9EJEWkTB+6iEi6U6CLiKQIBbqISIpQoIuIpAgFuohIilCgi4ikCAW6iEiK+H8d6jLD4xQBcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(val_loss_it, val_loss, 'b', label='Loss Value')\n",
    "plt.plot(val_loss_it, val_acc, 'r', label = 'ACC')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell I show som expected values and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3,  4,  5,  6, 21, 15, 16, 11, 39, 13,  5, 20, 87, 89,  9, 10, 17,  2,\n",
      "         0,  0,  0,  0,  0,  0], device='cuda:0')\n",
      "tensor([[ 3,  4,  5,  6, 21, 15, 16, 11, 39, 13,  5, 20, 87, 89,  9, 10, 17,  2]],\n",
      "       device='cuda:0')\n",
      "tensor([79,  5, 52, 84, 15, 85, 11, 12, 13,  5,  6, 69, 89,  9, 10, 17,  2,  0,\n",
      "         0,  0,  0,  0,  0,  0], device='cuda:0')\n",
      "tensor([[79,  5, 52, 84, 15, 85, 11, 12, 13,  5,  6, 69, 89,  9, 10, 17,  2]],\n",
      "       device='cuda:0')\n",
      "tensor([114, 225, 132, 294,  15,  83,  15,  27,  17,   2,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0], device='cuda:0')\n",
      "tensor([[114, 225, 132, 294,  15,  83,  15,  27,  17,   2]], device='cuda:0')\n",
      "tensor([ 41,  92,   5,  52, 188,  15,  27,  11,  12,  13,   5,   6,  84,  15,\n",
      "         32,  17,   2,   0,   0,   0,   0,   0,   0,   0], device='cuda:0')\n",
      "tensor([[ 41,  92,   5,  52, 188,  15,  27,  11,  12,  13,   5,   6,  84,  15,\n",
      "          32,  17,   2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for a, b in zip(fre, pred):\n",
    "    print(a[1:])\n",
    "    print(b.max(2)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Testing the model\n",
    "After training the model it is necessary to test it with the test data set. With this step we can determine if our model has an over-fit, and know what the final accuracy is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder_Decoder(\n",
       "  (emb1): Embedding(232, 200)\n",
       "  (emb2): Embedding(360, 250)\n",
       "  (LSTM1): LSTM(200, 200, batch_first=True, bidirectional=True)\n",
       "  (LSTM2): LSTM(250, 250, num_layers=2, batch_first=True)\n",
       "  (Dense1): Linear(in_features=800, out_features=250, bias=True)\n",
       "  (Dense2): Linear(in_features=250, out_features=1795, bias=True)\n",
       "  (Dense3): Linear(in_features=1795, out_features=359, bias=True)\n",
       "  (ELU1): ELU(alpha=1.0)\n",
       "  (ELU2): ELU(alpha=1.0)\n",
       "  (ELU3): ELU(alpha=1.0)\n",
       "  (relu1): ReLU()\n",
       "  (dropout1): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn =Encoder_Decoder(device='cpu')\n",
    "path = 'models/En2Fr_tr_best_model_enc_dec1.pkl'\n",
    "rnn.load_state_dict(torch.load(path))\n",
    "rnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value with the Test Dataset is:  0.027682218322199015\n",
      "The acc with the Test Dataset is:  0.9918897263981316\n"
     ]
    }
   ],
   "source": [
    "loss_va = 0\n",
    "acc_va = 0\n",
    "count_va = 0\n",
    "for eng, fre in te_ds:\n",
    "\n",
    "    eng = eng.to('cpu')\n",
    "    fre = fre.to('cpu')\n",
    "    pred = rnn(eng,fre)\n",
    "    \n",
    "    loss = loss_function(pred, fre, criterion, len(fr_t2id)).item() \n",
    "    acc = acc_function(pred, fre)\n",
    "    #count_va += pred.shape[0]\n",
    "    count_va += len(pred)\n",
    "    loss_va += loss * len(pred)\n",
    "    acc_va += acc * len(pred)\n",
    "\n",
    "\n",
    "loss_va = loss_va/count_va\n",
    "acc_va = acc_va/count_va\n",
    "print('The loss value with the Test Dataset is: ', loss_va)\n",
    "print('The acc with the Test Dataset is: ', acc_va)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "The loss value and score obtained with the test data set are better than expected after the validation result. The score is 0.991, which means that our model correctly predicts 99% of the words.\n",
    "\n",
    "After this great result it is important to remember the weaknesses of this model. To train it we have used an optimized dataset with a reduced vocabulary, which means that it is not ready for real life. Moreover, it is computationally very expensive and not optimal for situations where we need a large number of translations in a short time.\n",
    "\n",
    "The positive reading of this test is that it shows how powerful this architecture can be."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
